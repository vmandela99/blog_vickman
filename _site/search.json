[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Vickman",
    "section": "",
    "text": "Hi! My name is Victor Mandela Mokaya from Kenya üíú.\nI am leader, trainer and a coach in Evaluation, Research and Analysis. With my vast and strong background in generative AI, I have managed to guide, train and encourage very many professionals in different fields and at diverse positions across the globe for very many years.\nI harbor extensive expertise in managing field-based quantitative data collection, ensuring data quality, and designing research protocols. I have extensive proven ability to analyze and interpret quantitative data, train research teams, and translate findings into programmatic recommendations. I am super adept at generative AI tools for generating insights and informing policy decisions.\nI inspire strengths, leadership nurturing, capacity building and drive significant impact that has value to scale across the whole globe."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nR\n\n\nAnalysis\n\n\nVisualization\n\n\nStatistics\n\n\nRegression\n\n\nPractical Evaluation\n\n\n\n\n\n\n\n\n\nDec 5, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\nR\n\n\nStatistics\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nNov 11, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nThe Growing Importance of Wildlife Economy: A Path to Sustainable Growth\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\nStatistics\n\n\n\n\n\n\n\n\n\nNov 6, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Child Stunting in Ethiopia: Trends, Impacts, and Future Directions: USING DHS DATA\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\nR\n\n\nStatistics\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nOct 19, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\nR\n\n\nStatistics\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nOct 19, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nMonitoring and Evaluation in Health and Wellness: A Statistical Analysis Approach\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\n\n\n\n\n\n\n\nOct 18, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Develop a Research, Monitoring, and Evaluation Framework for Your Project\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\n\n\n\n\n\n\n\nOct 17, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build a Monitoring Plan for Your Project\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\n\n\n\n\n\n\n\nOct 17, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nHow to Build an Evaluation Plan for Your Project\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\n\n\n\n\n\n\n\nOct 17, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nKoboToolbox Introduction to Computer assistes programming interface(CAPI)\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nKoboToolbox\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nBest Practices for Survey Design and Field Management Using KoboToolbox\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nKoboToolbox\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nData Quality, Analysis, and Case Studies Using KoboToolbox\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nKoboToolbox\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey CTO Analysis, Challenges, and Future Trends\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nSurveyCTO\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey CTO Data Collection and Management\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nSurveyCTO\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey CTO Foundational Knowledge and Setup\n\n\n\n\n\n\nSurvey\n\n\nData Collection\n\n\nSurveyCTO\n\n\nCAPI\n\n\n\n\n\n\n\n\n\nOct 16, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nUnlocking Insights: A Step-by-Step Guide to Calculating Multidimensional Poverty Index (MPI) Using SPSS\n\n\n\n\n\n\nDemographicHealthSurvey\n\n\nStatistics\n\n\nSPSS\n\n\nMultidimensional Poverty Index (MPI)\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nOct 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nNavigating Financial Diaries Data: A Practical Guide to Analyzing Longitudinal Survey Data in R\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\nR\n\n\nStatistics\n\n\nSurvey\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nOct 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIntergrating Citizen Science Data in Conversation\n\n\n\n\n\n\nClimate\n\n\nGIS\n\n\nRegression\n\n\nR\n\n\nStatistics\n\n\nVisualization\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nWhy You Should Have a Portfolio Website: Documenting Your Experience for Success!\n\n\n\n\n\n\nSoft Skills\n\n\nWebsite\n\n\nProfile\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a website for free: Ultimate guide\n\n\n\n\n\n\nSoft Skills\n\n\nWebsite\n\n\nGit codes\n\n\nProfile\n\n\n\n\n\n\n\n\n\nSep 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nBoosting Team Performance\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nAug 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nReceived the Job, Excel and Word for Life!\n\n\n\n\n\n\nMonitoring and Evaluation\n\n\nSoft Skills\n\n\n\n\n\n\n\n\n\nAug 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDHS data - Convert Column Values into Column Headers in R\n\n\n\n\n\n\nDemographicHealthSurvey\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nDHS Survey Design Computation\n\n\n\n\n\n\nDemographicHealthSurvey\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nJul 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nProgress and Challenges: HIV Infections in Kenya from 2019 to 2021 Analysis with R\n\n\n\n\n\n\nVisualization\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nKenya Milk Export and Imports Analysis with R\n\n\n\n\n\n\nVisualization\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nApr 2, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nComparisons 01: Gender Equality Analysis Olympics\n\n\n\n\n\n\nVisualization\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nPotential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)\n\n\n\n\n\n\nVisualization\n\n\nStatistics\n\n\nR\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nMar 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nOrganizing Survey logistics\n\n\n\n\n\n\nSoft Skills\n\n\nSurvey\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 13, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nTraining staff\n\n\n\n\n\n\nSoft Skills\n\n\nSurvey\n\n\n\n\n\n\n\n\n\nFeb 10, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nCreating Beautiful Visualizations of Educational Attainment Using ggplot2 and ggbeeswarm\n\n\n\n\n\n\nVisualization\n\n\nStatistics\n\n\nR\n\n\n\n\n\n\n\n\n\nFeb 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGetting Weather Data via API with R\n\n\n\n\n\n\nGIS\n\n\nStatistics\n\n\nR\n\n\nAPI\n\n\nWeather Data\n\n\nClimate\n\n\n\n\n\n\n\n\n\nJan 31, 2024\n\n\nAlbert Rapp\n\n\n\n\n\n\n\n\n\n\n\n\nSurvey tools\n\n\n\n\n\n\nSoft Skills\n\n\nSurvey\n\n\n\n\n\n\n\n\n\nJan 20, 2024\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nMastering the Art of Task Juggling: A Simple Guide to Prioritizing and Multi-Tasking\n\n\n\n\n\n\nSoft Skills\n\n\n\n\n\n\n\n\n\nOct 14, 2022\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nMastering Project Management: A Simple Guide to Success\n\n\n\n\n\n\nSoft Skills\n\n\n\n\n\n\n\n\n\nAug 16, 2022\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nCrunching Numbers with a Smile: A Playful Guide to Elevating Mathematical and Analytical Skills in the Workplace\n\n\n\n\n\n\nSoft Skills\n\n\n\n\n\n\n\n\n\nAug 9, 2022\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nSpartial regression: Lesson3\n\n\n\n\n\n\nGIS\n\n\nStatistics\n\n\nR\n\n\nRegression\n\n\n\n\n\n\n\n\n\nJul 30, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial Data Manipulation in R: Lesson2\n\n\n\n\n\n\nGIS\n\n\nStatistics\n\n\nR\n\n\n\n\n\n\n\n\n\nJul 23, 2021\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial analysis with R: Lesson1\n\n\n\n\n\n\nGIS\n\n\nStatistics\n\n\nR\n\n\n\n\n\n\n\n\n\nJul 16, 2021\n\n\nVictor Mandela\n\n\n\n\n\n\n\n\n\n\n\n\nBusiness intelligence tools\n\n\n\n\n\n\nBI\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\nJul 9, 2021\n\n\nVictor Mandela\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Training_data_collection/index.html",
    "href": "posts/Training_data_collection/index.html",
    "title": "Training staff",
    "section": "",
    "text": "The competence of your field staff is pivotal to the success of your data collection program. When recruiting, prioritize individuals with a blend of domain expertise and technological proficiency. Ensure comprehensive training sessions that cover both survey tools and the intricacies of the data being collected.\n\n\nObjective: To simulate the process of using survey tools for data collection, specifically Google Forms, and to familiarize staff with the survey creation, distribution, and data retrieval processes.\nScenario: Imagine you are part of an agricultural organization tasked with collecting data on fruit preferences from participants attending a farmers‚Äô conference. The goal is to understand the most popular fruits among farmers for potential agricultural planning.\nSteps:\n\nCreate a Mock Survey:\n\nCreate a Google Form with questions related to fruit preferences. Include multiple-choice questions, checkboxes, and a text entry for comments.\nExample Questions:\n\nWhich fruit do you prefer the most? (Multiple-choice: Apple, Orange, Banana, Other)\nDo you grow any fruits on your farm? (Checkbox: Apple, Orange, Banana, Mango, Other)\nAny additional comments or suggestions?\n\n\nShare the Mock Survey:\n\nShare the Google Form with the training participants using a unique link.\nIn a real-world scenario, this link could be distributed via email, QR codes, or any other method.\n\nSimulate Data Collection:\n\nIn the training session, ask participants to fill out the mock survey using the provided link.\nEncourage them to use different devices such as smartphones, tablets, or laptops to simulate real-world conditions.\n\nReview Survey Responses:\n\nDemonstrate how to access and review survey responses in real-time.\nDiscuss how to analyze the collected data within the Google Forms interface.\n\nTroubleshooting Exercise:\n\nIntroduce common issues that may arise during data collection, such as incomplete submissions, errors in responses, or technical difficulties.\nEncourage participants to troubleshoot and find solutions collaboratively.\n\nFeedback and Discussion:\n\nFacilitate a discussion on the challenges faced during the mock data collection exercise.\nEncourage participants to share insights and lessons learned.\nProvide tips on improving the data collection process.\n\n\nBenefits:\n\nFamiliarity: Participants gain hands-on experience using the survey tool, making them more comfortable with its features.\nTroubleshooting Skills: Staff learn to identify and address issues that may arise during real data collection.\nTeam Collaboration: The exercise fosters teamwork as participants work together to solve challenges.\nFeedback Loop: Insights from the exercise can be used to enhance training materials and improve the actual data collection process.\n\nBy incorporating a mock data collection exercise into training, staff members can build practical skills and confidence, ensuring a smoother transition to actual fieldwork."
  },
  {
    "objectID": "posts/Training_data_collection/index.html#recruitment-and-training-of-data-collection-staff",
    "href": "posts/Training_data_collection/index.html#recruitment-and-training-of-data-collection-staff",
    "title": "Training staff",
    "section": "",
    "text": "The competence of your field staff is pivotal to the success of your data collection program. When recruiting, prioritize individuals with a blend of domain expertise and technological proficiency. Ensure comprehensive training sessions that cover both survey tools and the intricacies of the data being collected.\n\n\nObjective: To simulate the process of using survey tools for data collection, specifically Google Forms, and to familiarize staff with the survey creation, distribution, and data retrieval processes.\nScenario: Imagine you are part of an agricultural organization tasked with collecting data on fruit preferences from participants attending a farmers‚Äô conference. The goal is to understand the most popular fruits among farmers for potential agricultural planning.\nSteps:\n\nCreate a Mock Survey:\n\nCreate a Google Form with questions related to fruit preferences. Include multiple-choice questions, checkboxes, and a text entry for comments.\nExample Questions:\n\nWhich fruit do you prefer the most? (Multiple-choice: Apple, Orange, Banana, Other)\nDo you grow any fruits on your farm? (Checkbox: Apple, Orange, Banana, Mango, Other)\nAny additional comments or suggestions?\n\n\nShare the Mock Survey:\n\nShare the Google Form with the training participants using a unique link.\nIn a real-world scenario, this link could be distributed via email, QR codes, or any other method.\n\nSimulate Data Collection:\n\nIn the training session, ask participants to fill out the mock survey using the provided link.\nEncourage them to use different devices such as smartphones, tablets, or laptops to simulate real-world conditions.\n\nReview Survey Responses:\n\nDemonstrate how to access and review survey responses in real-time.\nDiscuss how to analyze the collected data within the Google Forms interface.\n\nTroubleshooting Exercise:\n\nIntroduce common issues that may arise during data collection, such as incomplete submissions, errors in responses, or technical difficulties.\nEncourage participants to troubleshoot and find solutions collaboratively.\n\nFeedback and Discussion:\n\nFacilitate a discussion on the challenges faced during the mock data collection exercise.\nEncourage participants to share insights and lessons learned.\nProvide tips on improving the data collection process.\n\n\nBenefits:\n\nFamiliarity: Participants gain hands-on experience using the survey tool, making them more comfortable with its features.\nTroubleshooting Skills: Staff learn to identify and address issues that may arise during real data collection.\nTeam Collaboration: The exercise fosters teamwork as participants work together to solve challenges.\nFeedback Loop: Insights from the exercise can be used to enhance training materials and improve the actual data collection process.\n\nBy incorporating a mock data collection exercise into training, staff members can build practical skills and confidence, ensuring a smoother transition to actual fieldwork."
  },
  {
    "objectID": "posts/Survey_CTO_Data Collection and Management/index.html",
    "href": "posts/Survey_CTO_Data Collection and Management/index.html",
    "title": "Survey CTO Data Collection and Management",
    "section": "",
    "text": "Understanding Data Collection in the Field When collecting data in the field, researchers go directly to the respondents, which can be households, businesses, or other locations, to gather information. This process can be challenging but is crucial for obtaining high-quality data.\nExample: Imagine a team conducting a survey on household energy use. Enumerators would visit homes to ask questions about energy sources, costs, and usage patterns.\nTips for Effective Data Collection\n\nTrain Enumerators: Ensure that your enumerators understand the survey instrument and are familiar with the technology they will use.\nExample: Conduct a training session where enumerators practice using SurveyCTO on their devices and role-play various interview scenarios.\nEstablish Clear Protocols: Create guidelines for how enumerators should conduct interviews, including how to approach respondents and handle refusals.\nExample: Provide enumerators with scripts to politely introduce themselves and explain the purpose of the survey to gain the respondent‚Äôs trust.\nUse Offline Capabilities: SurveyCTO allows data collection offline, which is especially useful in areas with poor internet connectivity.\nExample: Enumerators can collect data while visiting remote areas, and their responses will sync to the server once they have internet access."
  },
  {
    "objectID": "posts/Survey_CTO_Data Collection and Management/index.html#collecting-and-managing-data-in-the-field",
    "href": "posts/Survey_CTO_Data Collection and Management/index.html#collecting-and-managing-data-in-the-field",
    "title": "Survey CTO Data Collection and Management",
    "section": "",
    "text": "Understanding Data Collection in the Field When collecting data in the field, researchers go directly to the respondents, which can be households, businesses, or other locations, to gather information. This process can be challenging but is crucial for obtaining high-quality data.\nExample: Imagine a team conducting a survey on household energy use. Enumerators would visit homes to ask questions about energy sources, costs, and usage patterns.\nTips for Effective Data Collection\n\nTrain Enumerators: Ensure that your enumerators understand the survey instrument and are familiar with the technology they will use.\nExample: Conduct a training session where enumerators practice using SurveyCTO on their devices and role-play various interview scenarios.\nEstablish Clear Protocols: Create guidelines for how enumerators should conduct interviews, including how to approach respondents and handle refusals.\nExample: Provide enumerators with scripts to politely introduce themselves and explain the purpose of the survey to gain the respondent‚Äôs trust.\nUse Offline Capabilities: SurveyCTO allows data collection offline, which is especially useful in areas with poor internet connectivity.\nExample: Enumerators can collect data while visiting remote areas, and their responses will sync to the server once they have internet access."
  },
  {
    "objectID": "posts/Survey_CTO_Data Collection and Management/index.html#integrating-gps-and-multimedia-in-capi",
    "href": "posts/Survey_CTO_Data Collection and Management/index.html#integrating-gps-and-multimedia-in-capi",
    "title": "Survey CTO Data Collection and Management",
    "section": "2. Integrating GPS and Multimedia in CAPI",
    "text": "2. Integrating GPS and Multimedia in CAPI\nEnhancing Data Collection with Technology Integrating GPS and multimedia features in CAPI can enrich your data and provide valuable context to the responses collected.\nUsing GPS GPS functionality can help track the location where data is collected, which is especially useful for spatial analysis.\nExample: If you‚Äôre surveying agricultural practices, GPS data can pinpoint the locations of farms, allowing for a better understanding of regional farming trends.\nUsing Multimedia Incorporating multimedia elements like images, audio recordings, or videos can enhance the data collection process.\nExample: An interviewer might take photos of different energy sources (like solar panels or firewood) used by households during the energy use survey to provide visual context for the responses."
  },
  {
    "objectID": "posts/Survey_CTO_Data Collection and Management/index.html#data-security-and-privacy-considerations",
    "href": "posts/Survey_CTO_Data Collection and Management/index.html#data-security-and-privacy-considerations",
    "title": "Survey CTO Data Collection and Management",
    "section": "3. Data Security and Privacy Considerations",
    "text": "3. Data Security and Privacy Considerations\nImportance of Data Security When collecting sensitive information, it‚Äôs vital to ensure that the data is secure and that respondents‚Äô privacy is protected.\nTips for Ensuring Data Security\n\nUse Encrypted Data Transmission: SurveyCTO encrypts data, ensuring that it remains secure while being transmitted from devices to the server.\nExample: When an enumerator submits survey responses through their device, the data is encrypted, protecting it from unauthorized access.\nLimit Access to Data: Only allow authorized personnel to access the data collected to reduce the risk of breaches.\nExample: Set user roles in SurveyCTO so that only team leaders and data analysts can view sensitive data, while enumerators have limited access.\nObtain Informed Consent: Always inform respondents about how their data will be used and obtain their consent before collecting personal information.\nExample: During the introduction, the enumerator can explain, ‚ÄúYour responses will help us understand community energy needs. Your answers will remain confidential and will be used for research purposes only.‚Äù\n\nConclusion Effective data collection and management are crucial for the success of any research project. By implementing proper training, leveraging technology like GPS and multimedia, and prioritizing data security, you can enhance the quality and reliability of your data. In the upcoming posts, we‚Äôll explore how to analyze CAPI data effectively and discuss common challenges you might encounter. Stay tuned!"
  },
  {
    "objectID": "posts/Project management/index.html",
    "href": "posts/Project management/index.html",
    "title": "Mastering Project Management: A Simple Guide to Success",
    "section": "",
    "text": "Mastering Project Management: A Simple Guide to Success\n\nIntroduction:\nHello, project enthusiasts! Whether you‚Äôre a seasoned project manager or someone stepping into the world of coordinating tasks, we‚Äôre here to make project management a breeze. In this easy-to-understand guide, we‚Äôll explore how to boost your competence, ensure timely delivery, maintain high-quality output, and foster great communication. Let‚Äôs break it down without the jargon and make project success accessible to all!\n1. ‚ÄúCompetence: The ABCs of Mastery‚Äù\n\n\n\n\n\nImagine project management as a skill playground. Start by learning the basics ‚Äì understand your project‚Äôs objectives, scope, and team dynamics. Familiarize yourself with project management tools; they‚Äôre like the cool kids‚Äô toys that make your job easier. As you play in this skill playground, you‚Äôll naturally enhance your competence over time.\n2. ‚ÄúTimely Delivery: The Art of Time Management‚Äù\n\n\n\n\n\nThink of project timelines as a recipe ‚Äì break down the tasks into bite-sized pieces. Create a timeline that‚Äôs realistic and achievable. Use a calendar or a project management tool to keep everyone on the same page. Remember, punctuality is the secret ingredient to successful project delivery.\n3. ‚ÄúQuality Output: Crafting a Masterpiece‚Äù\n\n\n\n\n\nQuality output is like baking a cake ‚Äì you need the right ingredients and a foolproof recipe. Clearly define project requirements, encourage collaboration, and perform regular checks to ensure everything is baking ‚Äì or, in this case, developing ‚Äì smoothly. The result? A deliciously successful project!\n4. ‚ÄúGreat Communication: The Art of Conversation‚Äù\n\n\n\n\n\nPicture project communication as a friendly chat. Be clear, concise, and approachable. Share updates regularly and encourage open dialogue. Remember, good communication is a two-way street. Listen as much as you talk, and you‚Äôll find your project sailing smoothly.\n5. ‚ÄúCollaboration: Teamwork Makes the Dream Work‚Äù\n\n\n\n\n\nThink of your project team as a well-oiled machine. Encourage collaboration by creating a supportive environment. Clearly define roles, communicate openly, and celebrate achievements together. Remember, everyone plays a crucial part in the success of the project.\n\nConclusion:\nProject management doesn‚Äôt have to be a complex puzzle. Break it down into manageable steps, like assembling a Lego set. Start with the basics, manage your time wisely, focus on delivering quality, communicate openly, and foster teamwork. By simplifying project management, you‚Äôre not just ensuring success; you‚Äôre making the entire process enjoyable for everyone involved. So, grab your toolkit, put on your chef‚Äôs hat, and let‚Äôs cook up some project success together!"
  },
  {
    "objectID": "posts/Olympics gender equality analysis/index.html",
    "href": "posts/Olympics gender equality analysis/index.html",
    "title": "Comparisons 01: Gender Equality Analysis Olympics",
    "section": "",
    "text": "Inspired by Georgios KaramanisThis Chart is a contribution to day 1 of the hashtag#30DayChartChallengeHere are facts about the achievement of gender equality reported by www.olympic.com\nYou can get the code here on github 2024 Day 1 chart challenge\n\nCode snippet for Chart:\nlibrary(tidyverse)\nlibrary(ggforce)\nlibrary(camcorder)\n\ngg_record(dir = here::here(\"2024/01/\"), device = \"png\", width = 1080 * 2, height = 1350 * 2, units = \"px\", dpi = 320)\n\n# https://olympics.com/en/news/paris-2024-first-games-to-achieve-full-gender-parity\n\nr &lt;- 1.3\n\n\n\nwomen &lt;- tribble(\n ~olympics, ~year, ~pct, ~x0, ~y0, ~col,\n  \"Tokyo\", 1964, 13, 2*r - r/2, 3*r, \"#0081C8\",\n  \"Tokyo\", 2020, 48.7, 4*r, 3*r, \"black\",\n  \"Beijing\", 2022, 45, 6*r + r/2, 3*r, \"#EE334E\",\n  \"Bueno Aires\", 2018, 50, 3*r - r/4, 2*r, \"#FCB131\",\n  \"Lausanne\", 2020, 50, 5*r + r/4, 2*r, \"#00A651\"\n)\n\nf1 &lt;- \"Graphik\"\nf1b &lt;- \"Graphik Compact\"\nf2 &lt;- \"Produkt\"\nf2b &lt;- \"Produkt Medium\"\n\nggplot(women) +\n  # geom_circle(aes(x0 = x0, y0 = y0, r = 1.3, colour = col), linewidth = 8) +\n  geom_vline(aes(xintercept = x0), alpha = 0.1, linetype = \"dashed\") +\n  geom_arc_bar(aes(x0 = x0, y0 = y0, r = 1.5, r0 = 1.1, start = 0, end = 2 * pi), fill = \"grey99\", color = NA) +\n  geom_arc_bar(aes(x0 = x0, y0 = y0, r = 1.5, r0 = 1.1, fill = col, start = 0, end = pct * 2 * pi / 100), color = NA) +\n  geom_text(aes(x0, y0 + if_else(year %in% c(1932, 1992), -2.5, 2.5), label = paste0(olympics, year, \"\\n\", pct, \"%\"), color = col), lineheight = 0.9, family = f1, size = 5, fontface = \"bold\") +\n  annotate(\"text\", 5.25, 9, label = \"Olympics Gender Parity\\nWomen Equality\", family = f2b, color = \"purple4\", size = 14, lineheight = 0.8) +\n  annotate(\"text\", 5.25, -2, label = paste0(\"Source: www.olympics.com, \", 2023, \"\\n\", \"Graphic: VICTOR MANDELA\"), family = f2, color = \"purple4\") +\n  scale_color_identity() +\n  scale_fill_identity() +\n  coord_fixed(xlim = c(0.5, 10), ylim = c(-2, 10)) +\n  theme_void() +\n  theme(\n    plot.background = element_rect(fill = \"#C9E4DE\", color = NA)\n  )\nOlympic Movement: Achievements in gender equality\n\nParis 1900: Female athletes first took part in the Olympic Games, four years after the first modern Olympics took place in Athens\n1996: Promotion of women becomes a mission of the IOC and is enshrined in the Olympic Charter\nTokyo 2020: The last edition of the Games were the most gender-balanced to date with 48.7 per cent of athletes women. At Tokyo 1964, only 13 per cent of the athletes were women.\nTokyo 2020: Following a rule change allowing one male and one female athlete to jointly carry their flag during the Opening Ceremony, 91 per cent of NOCs had a female flag bearer\nTokyo 2020: Three disciplines achieved gender balance (BMX racing, mountain biking and freestyle wrestling)\n\n\n\n\nBeijing\n\n\n\nBeijing 2022: The last Olympic Winter Games were the most gender balanced to date with 45 per cent female athletes\nParis 2024: Out of the 10,500 athletes participating in the Games, 5,250 will be men and 5,250 women. These Games will be the first to reach full gender parity in terms of number of athletes.\nFemale IOC membership currently stands at 40 per cent, up from 21 per cent at the start of the Olympic Agenda 2020\n\n\n\n\nLausanne\n\n\n\nYouth Olympic Games: The Youth Games Buenos Aires 2018 and Winter Youth Games Lausanne 2020 reached full gender parity in overall athlete participation (2,000 athletes per gender in 2018 and 936 in 2020)\n\n\n\nBueno Aires 2018\n\n\nFemale representation on the IOC Executive Board stands at 33.3 per cent, versus 26.6 per cent before the Olympic Agenda 2020\n50 per cent of the members of IOC Commissions positions have been held by women since 2022, compared with 20.3 per cent prior to the Olympic Agenda 2020. In addition, a record high of 13 of the 31 commissions were chaired by women in 2022."
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html",
    "href": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html",
    "title": "Understanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA",
    "section": "",
    "text": "Morocco has seen significant changes in both life expectancy and healthy life expectancy (HALE) between 2000 and 2018. While life expectancy at birth has risen to 74.5 years, the number of years lived in full health (HALE) has decreased. This shift presents important insights for researchers interested in the health outcomes of the Moroccan population.\nIn this blog post, we will discuss the definitions of life expectancy and HALE, examine their trends in Morocco, and highlight the importance of focusing on quality of life alongside longevity. Our analysis is based on data from Global Health Estimates and Demographic and Health Surveys (DHS).\n\n\nLife expectancy is the average number of years a newborn is expected to live, assuming current mortality rates remain constant throughout their lifetime. It is often used as a benchmark to measure the health and development of a population.\nHealthy life expectancy (HALE), on the other hand, measures the number of years an individual can expect to live in good health, free from serious illnesses and disabilities. HALE provides a more comprehensive picture of population health by accounting for both mortality and the burden of disease.\n\n\n\nFrom 2000 to 2018, Morocco experienced an impressive increase in life expectancy, reaching 74.5 years in 2018. Several factors have contributed to this improvement, including:\n\nEnhanced healthcare systems and increased access to medical services.\nImprovements in nutrition, education, and living conditions.\nA significant reduction in infant and child mortality rates.\n\nThese changes have extended the lifespan of the population, signaling overall progress in Morocco‚Äôs health outcomes. However, a deeper look into HALE reveals a more complex reality.\n\n\n\nWhile life expectancy has risen, HALE has seen a decline in Morocco. This suggests that although people are living longer, many of these additional years are spent living with illnesses or disabilities. Chronic diseases, such as cardiovascular diseases, diabetes, and other non-communicable diseases (NCDs), have become more prevalent, affecting the quality of life during these later years.\nThis trend highlights a growing gap between total life expectancy and the number of years lived in good health. The burden of disease, especially NCDs, is a significant contributor to the reduction in HALE. As life expectancy increases, public health policies must focus on managing chronic illnesses to improve overall quality of life.\n\n\n\nThe life expectancy and HALE data for Morocco were sourced from the Global Health Estimates (GHE) and analyzed using standard statistical methods. HALE is calculated by adjusting life expectancy to account for years lived with illness or disability. This calculation provides a more accurate reflection of population health compared to life expectancy alone.\nDemographic and Health Surveys (DHS) also offer valuable insights into Morocco‚Äôs health trends. DHS data on maternal and child health, disease prevalence, and healthcare access play a crucial role in understanding how HALE is affected by various health determinants."
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#introduction",
    "href": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#introduction",
    "title": "Understanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA",
    "section": "",
    "text": "Morocco has seen significant changes in both life expectancy and healthy life expectancy (HALE) between 2000 and 2018. While life expectancy at birth has risen to 74.5 years, the number of years lived in full health (HALE) has decreased. This shift presents important insights for researchers interested in the health outcomes of the Moroccan population.\nIn this blog post, we will discuss the definitions of life expectancy and HALE, examine their trends in Morocco, and highlight the importance of focusing on quality of life alongside longevity. Our analysis is based on data from Global Health Estimates and Demographic and Health Surveys (DHS).\n\n\nLife expectancy is the average number of years a newborn is expected to live, assuming current mortality rates remain constant throughout their lifetime. It is often used as a benchmark to measure the health and development of a population.\nHealthy life expectancy (HALE), on the other hand, measures the number of years an individual can expect to live in good health, free from serious illnesses and disabilities. HALE provides a more comprehensive picture of population health by accounting for both mortality and the burden of disease.\n\n\n\nFrom 2000 to 2018, Morocco experienced an impressive increase in life expectancy, reaching 74.5 years in 2018. Several factors have contributed to this improvement, including:\n\nEnhanced healthcare systems and increased access to medical services.\nImprovements in nutrition, education, and living conditions.\nA significant reduction in infant and child mortality rates.\n\nThese changes have extended the lifespan of the population, signaling overall progress in Morocco‚Äôs health outcomes. However, a deeper look into HALE reveals a more complex reality.\n\n\n\nWhile life expectancy has risen, HALE has seen a decline in Morocco. This suggests that although people are living longer, many of these additional years are spent living with illnesses or disabilities. Chronic diseases, such as cardiovascular diseases, diabetes, and other non-communicable diseases (NCDs), have become more prevalent, affecting the quality of life during these later years.\nThis trend highlights a growing gap between total life expectancy and the number of years lived in good health. The burden of disease, especially NCDs, is a significant contributor to the reduction in HALE. As life expectancy increases, public health policies must focus on managing chronic illnesses to improve overall quality of life.\n\n\n\nThe life expectancy and HALE data for Morocco were sourced from the Global Health Estimates (GHE) and analyzed using standard statistical methods. HALE is calculated by adjusting life expectancy to account for years lived with illness or disability. This calculation provides a more accurate reflection of population health compared to life expectancy alone.\nDemographic and Health Surveys (DHS) also offer valuable insights into Morocco‚Äôs health trends. DHS data on maternal and child health, disease prevalence, and healthcare access play a crucial role in understanding how HALE is affected by various health determinants."
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#key-insights",
    "href": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#key-insights",
    "title": "Understanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA",
    "section": "Key Insights :",
    "text": "Key Insights :\n\nRising Life Expectancy: Morocco‚Äôs life expectancy increased steadily from 2000 to 2018, reaching 74.5 years, showcasing overall progress in health and longevity.\nDecreasing HALE: The decline in HALE underscores the need to focus not just on extending life but on improving the quality of those additional years.\nChronic Disease Burden: With the rise of NCDs, Morocco faces challenges in ensuring that its population can live longer, healthier lives. Addressing chronic illness is crucial to closing the gap between life expectancy and HALE.\nData-Driven Public Health: Utilizing high-quality data from sources like Global Health Estimates and DHS can inform policies aimed at enhancing healthcare systems and managing the burden of chronic diseases.\n\n\nHow to Analyze HALE and Life Expectancy\nFor data enthusiasts and researchers, analyzing HALE and life expectancy trends over time can be achieved through various statistical tools. In this blog, we‚Äôll provide an example analysis code using R to visualize these trends. The code will allow you to compare life expectancy at birth and HALE over time, shedding light on the growing disparity between longevity and healthy living years.\nGetting the data\n# Fetching the data\nmorocco_df &lt;- readr::read_csv(\"https://data.humdata.org/dataset/1f98948b-5c63-48c6-a92c-44cf2cec1e9f/resource/11c05ae5-ce13-4cbb-a888-f2175bb5266c/download/global_health_estimates_life_expectancy_and_leading_causes_of_death_and_disability_indicators_ma.csv\")\n\n\ntrans_morocco &lt;- morocco_df %&gt;% \n  filter(`DIMENSION (NAME)` == \"Female\") %&gt;% #choose females\n  select(`GHO (DISPLAY)`, `YEAR (DISPLAY)`, Numeric) %&gt;% # choose columns\n  group_by(`GHO (DISPLAY)`) %&gt;% \n  add_count(`YEAR (DISPLAY)`) %&gt;% #introduce a counting column\n    filter(n == 1) %&gt;% \n  pivot_wider(names_from = `GHO (DISPLAY)`,\n              values_from = Numeric) %&gt;% #change to wide format\n  arrange(`YEAR (DISPLAY)`) %&gt;% \n  drop_na() %&gt;% \n  select(1, 4, 5, 12, 13) # select the columns of interest\n\n#write_csv(trans_morocco, \"morocco_life_expectancy.csv\")\n#You can write the csv file to export to an external viz tool\n#I used datawrapper"
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#conclusion",
    "href": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#conclusion",
    "title": "Understanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA",
    "section": "Conclusion",
    "text": "Conclusion\nThe health improvements in Morocco over the past two decades are undeniable. Life expectancy has reached its highest point, but the decline in HALE raises questions about how long Moroccans are able to live in good health. As chronic diseases continue to affect the population, policymakers must shift their focus from merely extending life to improving the quality of those extra years.\nBy addressing these health challenges, Morocco can ensure that its aging population enjoys not just longer lives, but healthier ones too. For researchers and public health professionals, HALE provides a valuable metric that complements life expectancy, offering a fuller picture of a nation‚Äôs health."
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#references",
    "href": "posts/Monitoring_and_Evaluation_morocco_life_expectancy_HALE/index.html#references",
    "title": "Understanding Life Expectancy and Healthy Life Expectancy (HALE) in Morocco (2000-2018): USING DHS DATA",
    "section": "References",
    "text": "References\n\nWorld Health Organization (WHO). Global Health Estimates: Life Expectancy and Healthy Life Expectancy (HALE). Available at: WHO GHE\nDemographic and Health Surveys (DHS). Health data for Morocco. Available at: DHS Morocco\nInstitute for Health Metrics and Evaluation (IHME). Global Burden of Disease study. Available at: IHME\n\nFurther Reading and Data Resources (H2): For more in-depth data analysis and information on life expectancy and health outcomes, explore the following resources:\n\nWorld Bank Open Data: Country-specific health and development indicators.\nOur World in Data: Visualizations on global health, life expectancy, and disease burden.\nThe Lancet Global Health: Research on health trends and life expectancy in different regions."
  },
  {
    "objectID": "posts/MDPI_SPSS/index.html",
    "href": "posts/MDPI_SPSS/index.html",
    "title": "Unlocking Insights: A Step-by-Step Guide to Calculating Multidimensional Poverty Index (MPI) Using SPSS",
    "section": "",
    "text": "A Step-by-Step Guide to Calculating the Multidimensional Poverty Index (MPI) Using SPSS\nIn poverty research, the Multidimensional Poverty Index (MPI) is a crucial tool for measuring poverty beyond income, capturing deprivations across multiple dimensions such as education and living standards. This blog outlines the exact SPSS code to compute MPI using specific survey indicators.\nLet‚Äôs break down the process step by step:\n\nStep 1: Compute the MPI Indicators\nMPI is calculated based on two dimensions‚ÄîEducation and Living Standards‚Äîwith specific indicators for each. Here‚Äôs how you can compute the binary deprivation indicators for each component:\n\nEducation Indicators (Weight: 1/4 for each)\n\nYears of Schooling Completed\nCOMPUTE FIVE_YRS_SCHOOLING_COMPLETED = Q403b &lt; 5.\nSchool-Aged Child Enrollment\nCOMPUTE SCHOOL_AGED_CHILD_NOT_ENROLLED_IN_SCHOOL = Q404 = 1.\n\n\n\nLiving Standards Indicators (Weight: 1/12 for each)\n\nNo Electricity\nCOMPUTE No_electricity = Q409_1 = 0.\nAccess to Clean Drinking Water\nCOMPUTE ACCESS_TO_CLEAN_DRINKING_WATER = Q410 = 6 | Q410 = 7 | Q410 = 8 | Q410 = 10 | Q410 = 11 | Q410 = 12.\nAccess to Improved Sanitation\nCOMPUTE ACCESS_TO_IMPROVED_SANITATION = Q413 = 10 | Q413 = 11 | Q413 = 12 | Q413 = 13.\nDirt Floor\nCOMPUTE DIRT_FLOOR = Q407 = 1 | Q407 = 2.\nDirty Cooking Fuel\nCOMPUTE DIRTY_COOKING_FUEL = Q412 = 7 | Q412 = 8 | Q412 = 9 | Q412 = 10 | Q412 = 11 | Q412 = 12.\nAsset Holding\nCOMPUTE ASSET_HOLDING = (Q409_2 = 0 & Q409_3 = 0 & Q409_4 = 0 & Q409_6 = 0 & Q409_7 = 0 & Q409_8 = 0 & Q409_9 = 0) & (Q409_11 = 0 | Q409_12 = 0).\n\n\n\n\n\nStep 2: Weighting the Indicators\nAfter computing the individual indicators, apply the appropriate weights:\n\nEducation Indicators: Weight = 1/4\nLiving Standard Indicators: Weight = 1/12\n\nExample for the Years of Schooling Completed:\nCOMPUTE FIVE_YRS_SCHOOLING_COMPLETED_weighted = FIVE_YRS_SCHOOLING_COMPLETED * EDUCATION_WGHT.\nSimilarly, compute the weighted versions of all other indicators for education and living standards.\n\n\nStep 3: Calculate the Deprivation Score\nThe deprivation score is a sum of the weighted indicators, with scores ranging from 0 to 1, where 1 represents the highest deprivation.\nSyntax:\nCOMPUTE DEPRIVATION_SCORE = FIVE_YRS_SCHOOLING_COMPLETED_weighted + SCHOOL_AGED_CHILD_NOT_ENROLLED_IN_SCHOOL_weighted + No_electricity_WEIGHTED + ACCESS_TO_CLEAN_DRINKING_WATER_weighted + ACCESS_TO_IMPROVED_SANITATION_weighted + DIRT_FLOOR_weighted + DIRTY_COOKING_FUEL_weighted + ASSET_HOLDING_WEIGHTED.\n\n\n\nStep 4: MPI Classification\nFinally, classify households based on their deprivation scores:\n\nNon-Poor: 0-0.19\nVulnerable to Poverty: 0.20-0.33\nMultidimensionally Poor: 0.34-0.50\nSeverely Poor: 0.51+\n\nSyntax:\nRECODE DEPRIVATION_SCORE (0 thru 0.1999=1) (0.2000 thru 0.3333=2) (0.3334 thru 0.5000=3) (0.5001 thru Highest=4) INTO MPI_POVERTY_STATUS2.\n\n\nConclusion\nBy following these steps and using the corresponding SPSS code, you can efficiently compute the Multidimensional Poverty Index (MPI) and gain meaningful insights into poverty beyond income-based measures.\nMPI helps identify vulnerable populations, prioritize areas of intervention, and assess the overall well-being of households. If you‚Äôre interested in further understanding poverty data and the SPSS process, this guide serves as a comprehensive starting point!"
  },
  {
    "objectID": "posts/KobotoolBox_quality_analysis_case_study/index.html",
    "href": "posts/KobotoolBox_quality_analysis_case_study/index.html",
    "title": "Data Quality, Analysis, and Case Studies Using KoboToolbox",
    "section": "",
    "text": "Automating Quality Checks in CAPI Using KoboToolbox Features\nOne of the best features of KoboToolbox is its ability to automate quality checks during data collection. This ensures that the data you collect is clean and ready for analysis, reducing the need for time-consuming manual corrections later.\nHere‚Äôs how you can improve data quality with KoboToolbox:\n\nUse Validation Criteria\nKoboToolbox allows you to set validation rules for questions, ensuring that respondents enter data in the correct format. For example, if you‚Äôre collecting age data, you can set a rule that the age must be between 0 and 120. This prevents errors like entering ‚Äú500‚Äù as an age.\nExample: If your survey asks, ‚ÄúHow many children do you have?‚Äù you can set a validation rule to ensure the response is a number between 0 and 15, preventing incorrect entries.\nAdd Mandatory Questions\nYou can make certain questions mandatory so that respondents cannot skip them. This is particularly important for critical questions that are essential to your data analysis.\nExample: In a health survey, you can make the question ‚ÄúWhat is your gender?‚Äù mandatory, ensuring that no response is left out during the interview.\nUse Constraints for Logical Responses\nYou can set constraints to make sure answers are logical. For instance, if someone answers that they are 5 years old, a constraint can prevent them from answering that they have children, as this would be an illogical response.\nExample: If a respondent selects ‚ÄúNo‚Äù to the question ‚ÄúDo you own a mobile phone?‚Äù, you can add a constraint that prevents them from answering follow-up questions about phone usage, improving the survey‚Äôs flow.\nPreview and Test Before Data Collection\nAlways preview and test your survey before deployment to ensure that the validation criteria and constraints work as expected. Testing prevents errors during actual data collection.\nExample: Before deploying a survey on school attendance, preview it by entering test responses. This will show you if the logic and constraints work, such as preventing a respondent from entering ‚Äú10‚Äù when asked ‚ÄúHow many school days did you miss last month?‚Äù if the maximum allowed is 5.\n\n\n\nReal-Time Data Collection and Analysis with KoboToolbox\nOne of the most powerful features of KoboToolbox is the ability to collect and monitor data in real time. This gives you immediate insights into your survey results, enabling you to make adjustments on the fly and ensure data accuracy.\n\nMonitor Data as It‚Äôs Collected\nKoboToolbox allows you to view the incoming data while your field team is still collecting it. You can see the number of responses collected, check for any missing or incomplete data, and identify potential issues early on.\nExample: If you‚Äôre conducting a survey on household income, you can monitor the data to ensure all responses are complete. If you notice that a certain region is submitting fewer responses, you can contact your field team to address the issue before it becomes a bigger problem.\nExport Data for Analysis\nOnce the data is collected, you can export it to a variety of formats such as Excel, CSV, or even directly into statistical software like R or SPSS for deeper analysis. This allows you to clean and analyze the data as soon as it‚Äôs uploaded.\nExample: After completing a survey on water usage in rural areas, you can export the data to Excel, where you can filter responses and run simple analyses, such as calculating the average water consumption per household.\nVisualize Data Quickly\nKoboToolbox includes basic data visualization tools, allowing you to create simple graphs or charts directly on the platform. This is useful for quick insights without having to use other software.\nExample: If you‚Äôre collecting data on the types of crops grown in different regions, KoboToolbox lets you generate pie charts to see the proportion of households growing maize, beans, or other crops at a glance.\n\n\n\nHow to Visualize CAPI Data Collected via KoboToolbox\nVisualizing the data collected using KoboToolbox helps turn raw data into meaningful insights. Here‚Äôs how you can quickly create visualizations for your data:\n\nUse KoboToolbox‚Äôs Built-In Visualization\nKoboToolbox offers simple tools to visualize your survey results as bar charts, pie charts, or frequency tables. This is ideal for getting a quick overview of your data, especially if you need a snapshot during fieldwork.\nExample: After completing a survey on school enrollment, you can quickly create a pie chart to visualize the percentage of boys and girls enrolled in school.\nExport Data for Advanced Visualization\nIf you need more complex visualizations, export the data to Excel or a data visualization tool like Tableau. From there, you can create more detailed graphs, maps, or dashboards to better understand trends or patterns in your data.\nExample: After collecting data on household energy sources, you can export the data to Tableau and create a map that shows which regions rely more on firewood versus electricity, giving you a clearer picture of energy access in different areas.\nVisualize Trends Over Time\nIf your survey involves tracking data over time, you can create trend charts to visualize changes. This is especially useful in longitudinal studies where you need to monitor progress or compare results from different survey rounds.\nExample: If you‚Äôre running a survey on child nutrition over several months, you can use KoboToolbox‚Äôs export feature to create a line chart in Excel, showing how the average weight of children has changed over time.\n\n\n\nCase Study: Improving Health Data Collection with KoboToolbox CAPI\nTo illustrate the power of KoboToolbox, let‚Äôs look at a real-world case study of how it was used to improve health data collection in a rural setting.\nThe Challenge:\nA health NGO was tasked with collecting data on vaccination coverage in remote villages. Previously, they used paper surveys, which often led to errors, delays, and missing data. The team needed a more efficient way to gather accurate information in areas with no internet access.\nThe Solution:\nThe team switched to using KoboToolbox for CAPI. They designed a digital survey with validation rules and skip logic to ensure that only relevant questions were asked. The team collected data offline using the KoboCollect app and synced it later when they returned to areas with internet connectivity.\nResults:\n\nImproved Accuracy: With validation rules, errors were minimized. For example, respondents couldn‚Äôt enter invalid ages for children receiving vaccines.\nFaster Data Processing: Instead of waiting weeks for paper forms to be submitted and entered manually, data was available in real time, allowing the team to start analyzing it immediately.\nHigher Quality Data: By using mandatory fields and skip logic, the survey reduced missing responses and improved the overall quality of the data.\n\nExample: In one village, the NGO was able to quickly determine that vaccination coverage for measles was lower than expected, allowing them to take immediate action by organizing more vaccination clinics."
  },
  {
    "objectID": "posts/KDHS Survey Design/index.html",
    "href": "posts/KDHS Survey Design/index.html",
    "title": "DHS Survey Design Computation",
    "section": "",
    "text": "When working with Demographic and Health Surveys (DHS) data, it is crucial to understand certain standardized variables that are consistent across different countries and survey rounds. Three of these essential variables are v005, v021, and v022. These variables play a vital role in ensuring accurate and representative analysis of DHS data.\n\n\n\nThe v005 variable represents the sample weight for each individual in the survey. It is a six-digit number with 6 implied decimal places. Sample weights are used to adjust for the probability of selection, non-response, and other adjustments to ensure that the survey results are representative of the entire population. When analyzing DHS data, it is crucial to use these sample weights to obtain unbiased and accurate estimates.\n\n\n\n\nThe v021 variable indicates the primary sampling unit or cluster number. In DHS surveys, households are often grouped into clusters known as PSUs. This variable helps in accounting for the survey's complex design by identifying these clusters. Properly accounting for PSUs is essential for accurate variance estimation and analysis.\n\n\n\n\nThe v022 variable represents the sample stratum number. Stratification is a technique used in survey sampling to divide the population into different subgroups, or strata, based on certain characteristics. In DHS surveys, strata are often formed by geographic regions and urban/rural areas. This variable is important for specifying the stratification in the survey design, which is critical for proper weighting and variance estimation.\n\n\n\nTo effectively analyze DHS data, it is important to account for these variables in your statistical analysis. Here is an example of how to use these variables in R to set up\n# Install and load the survey package\ninstall.packages(\"survey\")\nlibrary(survey)\n\n# Assuming your DHS data is in a data frame called df\n# Create a survey design object\ndhs_design &lt;- svydesign(\n  id = ~v021,        # Primary Sampling Unit (PSU)\n  strata = ~v022,    # Strata\n  weights = ~v005,   # Sample weights\n  data = df,\n  nest = TRUE\n)\n\n# Now you can use the dhs_design object to perform weighted analyses\n\nThis setup allows you to correctly analyze the DHS data, taking into account the complex survey design, including clustering, stratification, and sampling weights.\n\n\n\nUnderstanding the roles of v005, v021, and v022 in DHS data is essential for accurate and representative analysis. By properly incorporating these variables into your analysis, you can ensure that your findings are both valid and reliable. Whether you are a seasoned researcher or new to DHS data, mastering these key variables will significantly enhance the quality of your analysis."
  },
  {
    "objectID": "posts/KDHS Survey Design/index.html#understanding-key-variables-in-dhs-data-v005-v021-and-v022",
    "href": "posts/KDHS Survey Design/index.html#understanding-key-variables-in-dhs-data-v005-v021-and-v022",
    "title": "DHS Survey Design Computation",
    "section": "",
    "text": "When working with Demographic and Health Surveys (DHS) data, it is crucial to understand certain standardized variables that are consistent across different countries and survey rounds. Three of these essential variables are v005, v021, and v022. These variables play a vital role in ensuring accurate and representative analysis of DHS data.\n\n\n\nThe v005 variable represents the sample weight for each individual in the survey. It is a six-digit number with 6 implied decimal places. Sample weights are used to adjust for the probability of selection, non-response, and other adjustments to ensure that the survey results are representative of the entire population. When analyzing DHS data, it is crucial to use these sample weights to obtain unbiased and accurate estimates.\n\n\n\n\nThe v021 variable indicates the primary sampling unit or cluster number. In DHS surveys, households are often grouped into clusters known as PSUs. This variable helps in accounting for the survey's complex design by identifying these clusters. Properly accounting for PSUs is essential for accurate variance estimation and analysis.\n\n\n\n\nThe v022 variable represents the sample stratum number. Stratification is a technique used in survey sampling to divide the population into different subgroups, or strata, based on certain characteristics. In DHS surveys, strata are often formed by geographic regions and urban/rural areas. This variable is important for specifying the stratification in the survey design, which is critical for proper weighting and variance estimation.\n\n\n\nTo effectively analyze DHS data, it is important to account for these variables in your statistical analysis. Here is an example of how to use these variables in R to set up\n# Install and load the survey package\ninstall.packages(\"survey\")\nlibrary(survey)\n\n# Assuming your DHS data is in a data frame called df\n# Create a survey design object\ndhs_design &lt;- svydesign(\n  id = ~v021,        # Primary Sampling Unit (PSU)\n  strata = ~v022,    # Strata\n  weights = ~v005,   # Sample weights\n  data = df,\n  nest = TRUE\n)\n\n# Now you can use the dhs_design object to perform weighted analyses\n\nThis setup allows you to correctly analyze the DHS data, taking into account the complex survey design, including clustering, stratification, and sampling weights.\n\n\n\nUnderstanding the roles of v005, v021, and v022 in DHS data is essential for accurate and representative analysis. By properly incorporating these variables into your analysis, you can ensure that your findings are both valid and reliable. Whether you are a seasoned researcher or new to DHS data, mastering these key variables will significantly enhance the quality of your analysis."
  },
  {
    "objectID": "posts/getting data from Api/index.html",
    "href": "posts/getting data from Api/index.html",
    "title": "Getting Weather Data via API with R",
    "section": "",
    "text": "I came across this awesome post from Albert Rapp about how to get weather data from API and I thought it was a great technique to use. Here we go.\n\nWhat is an API?\nWe are focusing on two APIs (application programming interfaces) for our project. Broadly speaking, an API is anything that we can throw code at to get results that we want.\nOften this refers to some data source that we tap into. But sometimes it also simply means the syntax of code. For example, ggplot2 has a very distinctive API, i.e.¬†a code syntax to create a chart.\nIn our current case, we will just refer to APIs as data sources and we will need to tap into two such APIs, namely these ones:\n\nUS National Weather Service API\nGoogle Geocoding API\n\nThe first one will give us weather forecasts based on specified coordinates and the second one will turn any address into coordinates for us. Today, we‚Äôll focus on the first one.\n\n\nMaking requests to an API\nIf you‚Äôve never worked with APIs, you know that it can feel like data is hidden away behind an API. Thankfully, the {httr2} package helps us a lot, even if we‚Äôve never dealt with APIs before.\nCase in point, my fellow YouTubeR (see what I did there? it‚Äôs ‚ÄúYouTube‚Äù and ‚ÄúR‚Äù) Melissa Van Bussel put together an excellent video that shows you how to use {httr2} to call the API of openAI or GitLab.\nAnyway, here‚Äôs how to make a request to an API to get data:\n\nNavigate to the URL the data can be accessed from\n(Optional depending on the API) Authenticate\nGet the response\n\nWith the National Weather Service, you can easily try this yourself. Just head to the following url using your web browser:\nhttps://api.weather.gov/points/38.8894,-77.0352\nIf you navigate there, you will get cryptic data like that:\n\nThis is what is known as a JSON file. More on that later. For now, notice that what you see at the end of the url after points/ corresponds to the coordinates that are given in the JSON output.\nThis means that the recipe for calling the weather API is simple: Append points/{lat},{long} at the end of the base_url, i.e.¬†https://api.weather.gov/. In this case, {lat},{long} corresponds to the latitude and longitude of the location you want to get weather forecasts for.\n\n\nMaking a request with {httr2}\nThe {httr2} syntax to make this work mimics this quite well. Here‚Äôs how it looks.\n\nBasically, at the core of every request is the request() function that needs to know the base_url. This returns an &lt;httr2_request&gt; object that can be passed to further req_*() functions to modify the request.\nHere, we used req_url_path_append() to modify the request but there are also other functions (and next week we‚Äôll learn about req_url_query()). Finally, to actually make the request, you can pass everything to req_perform().\n\n\n\nGetting the response\nAs you‚Äôve just seen, your request will return a &lt;httr2_response&gt; and if everything went well, the output will also show you Status: 200 OK. You can get the actual content (the JSON that you‚Äôve seen in your web browser earlier) via one of the many resp_*() functions that handle responses.\n\n\n\nWorking with the response\nAs you‚Äôve seen in the output, the JSON file you receive is structured as a highly nested list. To make sense of this data, we use glimpse() to understand the structure of the object\n\nAnd with¬†pluck()¬†you can easily drill down into specific parts of the list. For example, this could be used to get the URL for the hourly forecasts\n\n\n\nRepeat process for forecasts\nWith the new forecast URL, we can get new JSON data about the forecasts for our location.\n\nIn that output, we can see that there is a list called¬†periods¬†inside of the¬†properties¬†list that contains lists which always have 16 entries. This might be where our forecast data lives.\n\nAha! Each of those 16-entries lists seem to correspond to the forecast of one hour. Thus, to get the things like¬†temperature,¬†startTime,¬†probabilityOfPrecipitation, and¬†short_forecast¬†into a nice tibble format, we have to iterate over all of these 16-entries lists and wrap the values we want into a tibble.\n\nAnd once we have that data, we can transform the¬†time¬†column into a nice date-time object:\n\nThis was awesome. !"
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "",
    "text": "In the context of Kenya‚Äôs healthcare sector, absorption rate refers to the percentage of allocated funds that a county effectively uses for its intended purposes. A higher absorption rate indicates efficient utilization of resources, while lower rates may suggest inefficiency or mismanagement. Monitoring absorption rates is crucial for understanding the performance of local governments in implementing healthcare projects and services.\nLiterature Review\nStudies have shown that counties with higher absorption rates are often more effective in improving public health outcomes due to efficient fund allocation and management. According to research by the Controller of Budget, counties such as Mandera and West Pokot have demonstrated impressive absorption rates, while others like Kiambu and Kisii have struggled with lower utilization of funds (Controller of Budget, 2022). These disparities highlight a need for deeper analysis into what factors drive or hinder effective fund absorption across the regions."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#introduction-to-key-terms",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#introduction-to-key-terms",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "",
    "text": "In the context of Kenya‚Äôs healthcare sector, absorption rate refers to the percentage of allocated funds that a county effectively uses for its intended purposes. A higher absorption rate indicates efficient utilization of resources, while lower rates may suggest inefficiency or mismanagement. Monitoring absorption rates is crucial for understanding the performance of local governments in implementing healthcare projects and services.\nLiterature Review\nStudies have shown that counties with higher absorption rates are often more effective in improving public health outcomes due to efficient fund allocation and management. According to research by the Controller of Budget, counties such as Mandera and West Pokot have demonstrated impressive absorption rates, while others like Kiambu and Kisii have struggled with lower utilization of funds (Controller of Budget, 2022). These disparities highlight a need for deeper analysis into what factors drive or hinder effective fund absorption across the regions."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#methodology",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#methodology",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "Methodology",
    "text": "Methodology\n\nIn this analysis, I compiled data from the Controller of Budget‚Äôs website for the years 2015 to 2022, focusing on the healthcare budget allocations and absorption rates for Kenya‚Äôs 47 counties. Using this data, I created a time series visualization that tracks the absorption rates of the top 5 and bottom 5 counties in 2022."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#data-table-and-visualization",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#data-table-and-visualization",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "Data Table and Visualization",
    "text": "Data Table and Visualization\n\nThe table below summarizes the absorption rates for counties with the highest and lowest rates as of 2022:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCounty\nAbsorption Rate (2022)\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n\n\n\n\nWest Pokot\n95.4%\n114.74\n91.6\n78.1\n86.7\n83.3\n89.6\n85.2\n95.4\n\n\nMandera\n93.2%\n77.4\n84.8\n77.9\n87.8\n88.0\n88.4\n87.3\n93.2\n\n\nHoma Bay\n93.4%\n128.84\n85.2\n68.0\n67.8\n80.1\n83.0\n81.4\n93.4\n\n\nNakuru\n93.2%\n159.55\n70.7\n59.3\n54.9\n64.1\n66.2\n66.2\n93.2\n\n\nKirinyaga\n91.7%\n76.94\n81.0\n80.7\n87.4\n77.8\n82.4\n77.3\n91.7\n\n\n\nNote: These counties were selected based on their absorption rates in 2022.\nThe visualization below provides a clear representation of the trends over the years for the counties with the highest and lowest absorption rates."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#interpretation-of-the-data",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#interpretation-of-the-data",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "Interpretation of the Data",
    "text": "Interpretation of the Data\n\nFrom the table and the visualization, it is evident that counties such as West Pokot, Mandera, and Homa Bay have significantly improved their absorption rates, with each showing substantial increases from 2021 to 2022. Mandera, in particular, saw a remarkable 5.9% increase in its absorption rate from 2021. On the other hand, counties like Kiambu and Kisii experienced noticeable declines, highlighting inefficiencies in fund utilization. For example, Kiambu‚Äôs rate dropped from 73.2% in 2021 to 67.2% in 2022, which could indicate governance issues or inadequate monitoring of healthcare projects.\nImplications for Government, Donors, and Investors\nFor the Kenyan government, improving absorption rates should be a priority, as efficient use of funds directly impacts the delivery of healthcare services to the public. Lower absorption rates, especially in resource-rich counties like Kiambu, could result in missed opportunities for improving public health infrastructure. Donors and investors must consider the absorption rate when allocating funds to ensure that their contributions are being utilized effectively."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#recommendations-for-stakeholders",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#recommendations-for-stakeholders",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "Recommendations for Stakeholders",
    "text": "Recommendations for Stakeholders\n\nFor Government: Invest in capacity building for county governments to improve financial management and accountability.\nFor Donors: Focus funding in regions with high absorption rates, ensuring that resources are effectively utilized for public health projects.\nFor Investors: Look for investment opportunities in counties with high and improving absorption rates, as these regions are likely to see the most impactful growth in healthcare infrastructure."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#references",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#references",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "References",
    "text": "References\n\nController of Budget (2022). Annual County Government Budget Implementation Reports. Link.\nMinistry of Health (2022). Annual Health Sector Reports. Link."
  },
  {
    "objectID": "posts/Absorption_rates_trends_in_Kenya/index.html#practice-code-below",
    "href": "posts/Absorption_rates_trends_in_Kenya/index.html#practice-code-below",
    "title": "Understanding Absorption Rates and Their Implications in Kenya‚Äôs County Health Funding",
    "section": "Practice Code below",
    "text": "Practice Code below\n# Code for analysing the absorption rate.\n\nlibrary(tidyverse)\n\ndf &lt;- read_csv(\"full_df.csv\") %&gt;% \n  select(County, financial_year, absorption_rate) %&gt;% \n  mutate(year = case_when(financial_year == \"2014_2015\" ~ 2015,\n                          financial_year == \"2016_2017\" ~ 2016,\n                          financial_year == \"2017_2018\" ~ 2017,\n                          financial_year == \"2018_2019\" ~ 2018,\n                          financial_year == \"2019_2020\" ~ 2019,\n                          financial_year == \"2020_2021\" ~ 2020,\n                          financial_year == \"2021_2022\" ~ 2021,\n                          financial_year == \"2022_2023\" ~ 2022))\n\ntop_bottom_counties_2022 &lt;- df %&gt;%\n  filter(year == 2022) %&gt;%\n  arrange(desc(absorption_rate)) %&gt;%\n  slice(c(1:5, (n() - 4):n())) %&gt;%\n  pull(County)  # Extract the county names\n\n# Step 2: Filter the original data to get all years' records for the selected counties\ntop_bottom_counties_time_series &lt;- df %&gt;%\n  filter(County %in% top_bottom_counties_2022) %&gt;% \n  select(-financial_year) %&gt;% \n  pivot_wider(names_from = \"County\",\n              values_from = \"absorption_rate\")\n\nwrite_csv(top_bottom_counties_time_series, \"top_bottom_counties_by_absorption_rate.csv\")"
  },
  {
    "objectID": "posts/01_practical_analysis/index.html",
    "href": "posts/01_practical_analysis/index.html",
    "title": "Potential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)",
    "section": "",
    "text": "This document is presents the report from analysis conducted on Primary Education for the Ministry of Education (MINEDUC) in Rwanda. This report mainly focuses on rural and urban areas in\nsource of the data: here\nThe code below illustrates on how to load packages needed for the analysis\n#load package\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(broom)\nlibrary(purrr)\nThen we read in the data using the link to avoid wasting space and increase spead using tidyverse read_csv\ndata &lt;- read_csv(\"https://raw.githubusercontent.com/vmandela99/laterite-interview/master/laterite_education_data.csv\" )"
  },
  {
    "objectID": "posts/01_practical_analysis/index.html#the-task",
    "href": "posts/01_practical_analysis/index.html#the-task",
    "title": "Potential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)",
    "section": "",
    "text": "This document is presents the report from analysis conducted on Primary Education for the Ministry of Education (MINEDUC) in Rwanda. This report mainly focuses on rural and urban areas in\nsource of the data: here\nThe code below illustrates on how to load packages needed for the analysis\n#load package\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(broom)\nlibrary(purrr)\nThen we read in the data using the link to avoid wasting space and increase spead using tidyverse read_csv\ndata &lt;- read_csv(\"https://raw.githubusercontent.com/vmandela99/laterite-interview/master/laterite_education_data.csv\" )"
  },
  {
    "objectID": "posts/01_practical_analysis/index.html#introduction",
    "href": "posts/01_practical_analysis/index.html#introduction",
    "title": "Potential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)",
    "section": "Introduction",
    "text": "Introduction\nThe first task would be to clean the names, check for missing values, undestand the column names, check the data types and, also make sure that the data is in tidy format.\nThe following code is for renaming the columns for the to have meaningful names\n## rename the variables\nnames(data)\nr_data &lt;- data %&gt;% rename(Sex = s1q1, \n                          Age=s1q3y, \n                          region_class = ur2012,\n                          Father_alive=s1q13,\n                          Mother_alive = s1q14, \n                          health_prob=s3q4,\n                          Grade_2012=s4aq6a ,\n                          Grade_2013=s4aq6b , \n                          sch_attended_prev_yr=s4aq8, \n                          prob_in_sch=s4aq9,\n                          edu_expenses=s4aq11h,                         paid_edu_expenses_year_end=s4aq12 , \n                          sch_days_missed=s4aq14, \n                          why_not_attending_sch=s4aq15,\n                          why_leave_sch=s4aq17,\n                          can_read=s4bq3,\n                          can_write=s4bq4,\n                          can_calculate=s4bq5,\n                          farm_work=s6aq2)\n\nThen we define the missing values as NAs then remove them from the two variables. But this is always advisable after you have inquired from other departments why the data is missing in the first place. Beware that some missing data can not just be deleted, instead there are a couple of imputing techniques that we discuss the upcoming blogs. For now we illustrate how to delete them.\ndata &lt;- data %&gt;% \n  na_if(\"\") %&gt;% \n  filter(!is.na(Grade_2012),!is.na(Grade_2013))\nThis report investigates the causes of repetiton in primary education. Rural area here mean that the setting of the school location has low standards of living status and low population to infrastructure ratio while urban is the opposite."
  },
  {
    "objectID": "posts/01_practical_analysis/index.html#descriptive-analysis",
    "href": "posts/01_practical_analysis/index.html#descriptive-analysis",
    "title": "Potential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)",
    "section": "Descriptive analysis",
    "text": "Descriptive analysis\n\nProvinces\nThe report was mainly done in Rwanda where 5 provinces were considered. The provinces were Kigali city, Southern province, Western province, Northern Province and Eastern province. The table below summarises the percentage distribution of students from each province. Kigali city had 22.15 percent which was the highest numbers from a province in this study. However, the rest of the provinces had a nearly similar number with Southern province having the lowest number of students at 17.1 percent.\nThis is R code used to produce the table\ntable(r_data$province)-&gt;tabb\nprop.table(tabb)*100-&gt;tabb1\ntabb1%&gt;% knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVar1\n\nFreq\n\n\n\n\n\n\n\n\n\n\n\nKigali City\n\n22.15247\n\n\n\n\n\n\n\n\n\n\n\nSouthern Province\n\n17.10015\n\n\n\n\n\n\n\n\n\n\n\nWestern Province\n\n21.13602\n\n\n\n\n\n\n\n\n\n\n\nNorthern Province\n\n18.83408\n\n\n\n\n\n\n\n\n\n\n\nEastern Province\n\n20.77728\n\n\n\n\n\n\n\n\n\n\n\n\n\nDistricts\nThe report also looked at the following districts in Rwanda which are; Nyarugenge,Gasabo,Kicukiro,Nyanza,Gisagara,Nyaruguru,HuyeNyamagabe,Ruhango,Muhanga,Kamonyi,Karongi,RutsiroRubavu,Nyabihu,Ngororero,Rusizi,Nyamasheke,Rulindo,Gakenke,Musanze,Burera,Gicumbi,Rwamagana,Nyagatare,Gatsibo,Kayonza,Kirehe,Ngoma,Bugesera. The table below summarises the percentage distribution of students from each district. For this study, Gesabu had the highest number of student, 357 and Huye had the lowest number, which is 31 students.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVar1\n\nFreq\n\n\n\n\n\n\n\n\n\n\n\nNyarugenge\n\n133\n\n\n\n\n\n\n\n\n\n\n\nGasabo\n\n357\n\n\n\n\n\n\n\n\n\n\n\nKicukiro\n\n251\n\n\n\n\n\n\n\n\n\n\n\nNyanza\n\n43\n\n\n\n\n\n\n\n\n\n\n\nGisagara\n\n122\n\n\n\n\n\n\n\n\n\n\n\nNyaruguru\n\n125\n\n\n\n\n\n\n\n\n\n\n\nHuye\n\n31\n\n\n\n\n\n\n\n\n\n\n\nNyamagabe\n\n66\n\n\n\n\n\n\n\n\n\n\n\nRuhango\n\n82\n\n\n\n\n\n\n\n\n\n\n\nMuhanga\n\n61\n\n\n\n\n\n\n\n\n\n\n\nKamonyi\n\n42\n\n\n\n\n\n\n\n\n\n\n\nKarongi\n\n86\n\n\n\n\n\n\n\n\n\n\n\nRutsiro\n\n62\n\n\n\n\n\n\n\n\n\n\n\nRubavu\n\n72\n\n\n\n\n\n\n\n\n\n\n\nNyabihu\n\n110\n\n\n\n\n\n\n\n\n\n\n\nNgororero\n\n109\n\n\n\n\n\n\n\n\n\n\n\nRusizi\n\n92\n\n\n\n\n\n\n\n\n\n\n\nNyamasheke\n\n176\n\n\n\n\n\n\n\n\n\n\n\nRulindo\n\n75\n\n\n\n\n\n\n\n\n\n\n\nGakenke\n\n162\n\n\n\n\n\n\n\n\n\n\n\nMusanze\n\n104\n\n\n\n\n\n\n\n\n\n\n\nBurera\n\n179\n\n\n\n\n\n\n\n\n\n\n\nGicumbi\n\n110\n\n\n\n\n\n\n\n\n\n\n\nRwamagana\n\n58\n\n\n\n\n\n\n\n\n\n\n\nNyagatare\n\n127\n\n\n\n\n\n\n\n\n\n\n\nGatsibo\n\n88\n\n\n\n\n\n\n\n\n\n\n\nKayonza\n\n114\n\n\n\n\n\n\n\n\n\n\n\nKirehe\n\n106\n\n\n\n\n\n\n\n\n\n\n\nNgoma\n\n145\n\n\n\n\n\n\n\n\n\n\n\nBugesera\n\n57\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpread by region\nThe study divided region into four regions depending on the economic and development status. The regions considered in this study include;- Urban, rural, semi-urban and peri-urban regions. The table below show that the highest number was from the rural region having 75,5 percent of the number of students in this study. This shows that the researcher chose higher samples from the population from the rural set-up which might be suspected to have high turn over of repeating in grades.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVar1\n\nFreq\n\n\n\n\n\n\n\n\n\n\n\nPeri urban\n\n15.6950673\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n8.0119581\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n75.4559043\n\n\n\n\n\n\n\n\n\n\n\nSemi urban\n\n0.8370703\n\n\n\n\n\n\n\n\n\n\n\n\n\nGender Distribution\nThe study tried to sample an equal number of students in respect to gender. This is shown by the table below where the ratio of famales to men was almost one to one.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVar1\n\nFreq\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n50.9417\n\n\n\n\n\n\n\n\n\n\n\nMale\n\n49.0583"
  },
  {
    "objectID": "posts/01_practical_analysis/index.html#analysis",
    "href": "posts/01_practical_analysis/index.html#analysis",
    "title": "Potential causes of repetition and dropout in Primary Education covering Primary 1 (P1) to Primary 6 case study: Rural and Urban areas(P6)",
    "section": "Analysis",
    "text": "Analysis\n\nRepetition within grades in Primary Education\nThis analysis shows the findings of how repetition in grades in primary school varies across grades in school. It can be seen that at the time of study, apart from primary 1 having the highest number of students, 39.5 percent of the 686 pupils in that class had actually repeated the same grade from 2012. The other classes with the highest repetition rate are primary 2 (23.6 percent of 470), primary 5 (22.3 percent of 260), primary 3 (16.8 percent of 392) and primary 4 (16.7 percent of 305). It is also worthy noting that from post primary 1 to post primary 5 there was no cases of repetiton from 2012.\nThe R code of producing this is\n## how grade repetition varies by grade in Primary Education \ncomparis &lt;- data %&gt;% filter(!(Grade_2012%in%c(\"Not in class\")))\ntable(comparis$Grade_2012,comparis$repeated)-&gt;comparison_repetition_in_classes_2012\nprop.table(comparison_repetition_in_classes_2012,1)*100-&gt;tabwew\ntabwew %&gt;% knitr::kable()\n\nggplot(comparis, aes(x=repeated))+ geom_bar(position = \"dodge\")+facet_wrap(~Grade_2012)\nggplot(comparis, aes(x=Grade_2012,fill =repeated))+ geom_bar(position = \"stack\")+coord_flip()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFALSE\n\nTRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost primary 1\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost primary 3\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost primary 4\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost primary 5\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nPre-primary\n\n95.88235\n\n4.117647\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 1\n\n60.49563\n\n39.504373\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 2\n\n76.38298\n\n23.617021\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 3\n\n83.16327\n\n16.836735\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 4\n\n83.27869\n\n16.721311\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 5\n\n77.69231\n\n22.307692\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrimary 6,7,8\n\n93.19728\n\n6.802721\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 1\n\n97.67442\n\n2.325581\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 2\n\n90.56604\n\n9.433962\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 3\n\n94.11765\n\n5.882353\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 4\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 5\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecondary 6\n\n100.00000\n\n0.000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMales equally likely to drop out as females.\nThe research also wanted to check which gender had a higher drop out rate. The results showed a comparisons which was not significate between the two genders (since t.test for which variance is same showes a p-value of 0.9765 using Welch two sample test, which is &gt; 0.05). This shows that the two means of the genders were almost equal and therefore the conclusion would be that both male and female pupils had equal chances of dropping out from school.\n\n\nRegression analysis\nIn with the aim of investigating the determinants contributing to increase in rate of repetition, the researcher opted to consider the following predictor variables;- the weight, age, whether the father or mother was alive or not, the health problems suffered in the last 4 weeks, grade attended in during 2012 and 2013, who paid for the student expenses for the last 12 months and the reason why they(pupils who missed) didnt attend school. The response variable would be repeating a grade in school which would be binary,where 1 would mean repeated is true and 0 if otherwise. A binary logistic regression model was used. The predictor with p-value that were less than 0.05 were reported as significant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregion_class\n\n\n\n\n\n\n\n\n\n\n\n\nterm\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\n\n\n\n\n\n\n\n\n\n\n\n\nstd.error\n\n\n\n\n\n\n\n\n\n\n\n\np.value\n\n\n\n\n\n\n\n\n\n\n\n\np.adjusted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 5\n\n\n\n\n\n\n\n\n\n\n\n\n2.6246517\n\n\n\n\n\n\n\n\n\n\n\n\n0.1333536\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 6,7,8\n\n\n\n\n\n\n\n\n\n\n\n\n2.3926222\n\n\n\n\n\n\n\n\n\n\n\n\n0.1510041\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 4\n\n\n\n\n\n\n\n\n\n\n\n\n2.2149811\n\n\n\n\n\n\n\n\n\n\n\n\n0.1142086\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 3\n\n\n\n\n\n\n\n\n\n\n\n\n1.8104449\n\n\n\n\n\n\n\n\n\n\n\n\n0.0960966\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 2\n\n\n\n\n\n\n\n\n\n\n\n\n1.3240467\n\n\n\n\n\n\n\n\n\n\n\n\n0.0711579\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 1\n\n\n\n\n\n\n\n\n\n\n\n\n0.7385963\n\n\n\n\n\n\n\n\n\n\n\n\n0.0481840\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nprob_in_schMediocre teaching\n\n\n\n\n\n\n\n\n\n\n\n\n-0.3153225\n\n\n\n\n\n\n\n\n\n\n\n\n0.0858360\n\n\n\n\n\n\n\n\n\n\n\n\n0.0002598\n\n\n\n\n\n\n\n\n\n\n\n\n0.0220845\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Pre-primary\n\n\n\n\n\n\n\n\n\n\n\n\n-0.5500117\n\n\n\n\n\n\n\n\n\n\n\n\n0.1059252\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000003\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000259\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 1\n\n\n\n\n\n\n\n\n\n\n\n\n-0.7292078\n\n\n\n\n\n\n\n\n\n\n\n\n0.0599060\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Secondary 4\n\n\n\n\n\n\n\n\n\n\n\n\n-0.8776014\n\n\n\n\n\n\n\n\n\n\n\n\n0.1657405\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000002\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000154\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 2\n\n\n\n\n\n\n\n\n\n\n\n\n-1.4516728\n\n\n\n\n\n\n\n\n\n\n\n\n0.0739026\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Secondary 1\n\n\n\n\n\n\n\n\n\n\n\n\n-1.9269528\n\n\n\n\n\n\n\n\n\n\n\n\n0.4238364\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000066\n\n\n\n\n\n\n\n\n\n\n\n\n0.0005706\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 3\n\n\n\n\n\n\n\n\n\n\n\n\n-2.0677477\n\n\n\n\n\n\n\n\n\n\n\n\n0.0893855\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 4\n\n\n\n\n\n\n\n\n\n\n\n\n-2.5562536\n\n\n\n\n\n\n\n\n\n\n\n\n0.1099310\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 5\n\n\n\n\n\n\n\n\n\n\n\n\n-2.9426288\n\n\n\n\n\n\n\n\n\n\n\n\n0.1245526\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Secondary 1\n\n\n\n\n\n\n\n\n\n\n\n\n-3.1527569\n\n\n\n\n\n\n\n\n\n\n\n\n0.1589982\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRural\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 6,7,8\n\n\n\n\n\n\n\n\n\n\n\n\n-3.4075162\n\n\n\n\n\n\n\n\n\n\n\n\n0.1413879\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe table above show the findings of analysis from the rural area in rwanda where only problems experienced in school, grade in 2012 and 2013 were significant, we took . It shows that in 2012, pupils in primary 5,(6 to 8),4,3,2 and 1 were 13.73, 10.91, 9.12, 6.11, 3.74, 2.09 times more likely to repeat the same grade, in that order, than the students in post primary 1. Other hand, in 2013, pupils in pre-primary were 27 percent less likely to repeat the same grade as compared to those in post primary 1 in 2013. Further, those in primary 6, 7, 8 in 2013, were the least likely to repeat, i.e, 96.7 percent less likely to repeat as compared to post primary 1 in 2013.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nregion_class\n\n\n\n\n\n\n\n\n\n\n\n\nterm\n\n\n\n\n\n\n\n\n\n\n\n\nestimate\n\n\n\n\n\n\n\n\n\n\n\n\nstd.error\n\n\n\n\n\n\n\n\n\n\n\n\np.value\n\n\n\n\n\n\n\n\n\n\n\n\np.adjusted\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 5\n\n\n\n\n\n\n\n\n\n\n\n\n2.531815\n\n\n\n\n\n\n\n\n\n\n\n\n0.3913698\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 4\n\n\n\n\n\n\n\n\n\n\n\n\n1.737260\n\n\n\n\n\n\n\n\n\n\n\n\n0.3011179\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000003\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000270\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 3\n\n\n\n\n\n\n\n\n\n\n\n\n1.507446\n\n\n\n\n\n\n\n\n\n\n\n\n0.2891581\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000024\n\n\n\n\n\n\n\n\n\n\n\n\n0.0002122\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 2\n\n\n\n\n\n\n\n\n\n\n\n\n1.188648\n\n\n\n\n\n\n\n\n\n\n\n\n0.2228084\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000015\n\n\n\n\n\n\n\n\n\n\n\n\n0.0001380\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2012Primary 1\n\n\n\n\n\n\n\n\n\n\n\n\n0.803433\n\n\n\n\n\n\n\n\n\n\n\n\n0.1679609\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000116\n\n\n\n\n\n\n\n\n\n\n\n\n0.0009979\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Secondary 1\n\n\n\n\n\n\n\n\n\n\n\n\n-1.497037\n\n\n\n\n\n\n\n\n\n\n\n\n0.4055512\n\n\n\n\n\n\n\n\n\n\n\n\n0.0004833\n\n\n\n\n\n\n\n\n\n\n\n\n0.0401101\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Secondary 5\n\n\n\n\n\n\n\n\n\n\n\n\n-1.829716\n\n\n\n\n\n\n\n\n\n\n\n\n0.4934564\n\n\n\n\n\n\n\n\n\n\n\n\n0.0004582\n\n\n\n\n\n\n\n\n\n\n\n\n0.0384918\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 2\n\n\n\n\n\n\n\n\n\n\n\n\n-1.922012\n\n\n\n\n\n\n\n\n\n\n\n\n0.3655888\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000020\n\n\n\n\n\n\n\n\n\n\n\n\n0.0001822\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 3\n\n\n\n\n\n\n\n\n\n\n\n\n-2.367172\n\n\n\n\n\n\n\n\n\n\n\n\n0.3945070\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000001\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000115\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 4\n\n\n\n\n\n\n\n\n\n\n\n\n-2.724553\n\n\n\n\n\n\n\n\n\n\n\n\n0.4261606\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 5\n\n\n\n\n\n\n\n\n\n\n\n\n-2.922021\n\n\n\n\n\n\n\n\n\n\n\n\n0.4293049\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000005\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUrban\n\n\n\n\n\n\n\n\n\n\n\n\nGrade_2013Primary 6,7,8\n\n\n\n\n\n\n\n\n\n\n\n\n-3.963184\n\n\n\n\n\n\n\n\n\n\n\n\n0.5191857\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n0.0000000\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe table above as shows a snap short of the analysis of urban areas in Rwanda. As compared to the rural areas, the urban pupil were less likely to repeat, as shown in the table.\n\n\nStrengths and weakness of the data\n\nThe advantages of this data is that;-\n\nThe variables were specific since it was mainly focused in the rural areas.\nThe data was reliable because it did not have many outliers in the variables.\nThe data was observational and designed to control for gender as a cofounding variable\n\n\n\nThe disadvantages of this data was that;-\n\nIt had alot of missing values\n\n\n\nThe variables were highly correlated as shown from some of the test that has been conducted.\nThe data was collected not clean and needed some transformation.\nSome of the variable were not suitable to answer the main object of students repeating or passing."
  },
  {
    "objectID": "posts/Creating a profile Website/index.html",
    "href": "posts/Creating a profile Website/index.html",
    "title": "Creating a website for free: Ultimate guide",
    "section": "",
    "text": "Tools needed\nNote that you don‚Äôt have to have expert programming for this course.\nIn preparation we need the following:-\nR - https://cran.r-project.org/bin/windows/base/\nRstudio - https://rstudio.com/products/rstudio/download/\ngit for desktop- https://git-scm.com/downloads\nAlso, you need to create an account with:-¬†\nnetlify - https://www.netlify.com/\ngithub - https://github.com/\nSetting up R and R studio(positron) or any other IDE\n\nInstall the R and R studio.\nAlternative you can install Pycharm, VSCode\nAlternatively you can use Jupiter Notebook\n\n\nConnect rstudio to github account\n\nGo to rstudio &gt; tools &gt; Global options &gt;¬† GIT/SVN¬† &gt; SSH RSA key &gt; Create RSA key &gt; view public key &gt; copy\nGo to github &gt; Settings (top right corner) &gt; SSH and GPG keys &gt; SSH keys &gt;¬† New SSH key &gt; title (put your name) &gt; key (paste the public key) &gt; add SSH key\n\nSet up the git for desktop\n\ngit config ‚Äìglobal user.name ‚Äòyour github name‚Äô\ngit config ‚Äìglobal user.email ‚Äòemail address you used on github‚Äô\ngit config ‚Äìglobal ‚Äìlist\n\nCreate repository and clone it on github\n\nOpen your github account and create new repository\nClone the repository\n\n\nPicture Source: FAOStats"
  },
  {
    "objectID": "posts/How to build a shinyapp/index.html",
    "href": "posts/How to build a shinyapp/index.html",
    "title": "How to build a ShinyApp",
    "section": "",
    "text": "We begin to demonstrate the building blocks of a shinyApp.\nAn App needs a *User interface (ui)* and a server. The majic about the *shiny package* is that it can create both of this within R, plus run your app using an additionational shiny function.\nFirst,\n\nload the library using the shiny.\n\n\nlibrary(shiny)\n\n\nCreate ui using the html function\n\n\nui &lt;- fluidPage()\n\n\nDefine a custom function to create the server\n\n\nserver &lt;- function(input,\n\noutput,\n\nsession){\n\n}\n\n\nfinally run your app.\n\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/How to build a shinyapp/index.html#building-a-hello-world-shinyapp",
    "href": "posts/How to build a shinyapp/index.html#building-a-hello-world-shinyapp",
    "title": "How to build a ShinyApp",
    "section": "",
    "text": "We begin to demonstrate the building blocks of a shinyApp.\nAn App needs a *User interface (ui)* and a server. The majic about the *shiny package* is that it can create both of this within R, plus run your app using an additionational shiny function.\nFirst,\n\nload the library using the shiny.\n\n\nlibrary(shiny)\n\n\nCreate ui using the html function\n\n\nui &lt;- fluidPage()\n\n\nDefine a custom function to create the server\n\n\nserver &lt;- function(input,\n\noutput,\n\nsession){\n\n}\n\n\nfinally run your app.\n\n\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "posts/How to build a shinyapp/index.html#example1-of-shiny-app",
    "href": "posts/How to build a shinyapp/index.html#example1-of-shiny-app",
    "title": "How to build a ShinyApp",
    "section": "Example1 of shiny app",
    "text": "Example1 of shiny app\n\nlibrary(shiny)\n\nlibrary(widgetframe)\n\nui &lt;- fluidPage(\n\n\"Hello, world!!!!!!\"\n\n)\n\nserver &lt;- function(input,\n\noutput,\n\nsession){\n\n}\n\nshinyApp(ui = ui, server = server)\n\n\nExample2: Add a question\nWe want to go an extra mile an add a text that asks a question. This is possible but adding *textinput* function that allows us to enter text. It has three arguments, a unique ID that will be used to refer to this input, a label that is displayed to the user and an optional default value.\nOur full out put that is diplayed is contained in the server using the render text function. Inside of that you can use *paste* to create a longer character string. And if add *input$name* you can access the name added using text input. The text is assigned to an output object that will be used in the ui to display.\n\nlibrary(shiny)\n\nlibrary(widgetframe)\n\nui &lt;- fluidPage(\n\ntextInput(\"name\", \"Enter your name:\"),\n\ntextOutput(\"r\")\n\n)\n\nserver &lt;- function(input, output){\n\noutput$r &lt;- renderText({\n\npaste0(\"Do you prefer rain or sunshine,\", input$name, \"?\")\n\n})\n\n}\n\nshinyApp(ui = ui, server = server)\n\nYou did it a text that uses a text input!!"
  },
  {
    "objectID": "posts/KobotoolBox_design_n_management/index.html",
    "href": "posts/KobotoolBox_design_n_management/index.html",
    "title": "Best Practices for Survey Design and Field Management Using KoboToolbox",
    "section": "",
    "text": "Designing Effective Surveys for CAPI with KoboToolbox\nCreating well-structured surveys is key to collecting accurate and useful data. With KoboToolbox, you can design surveys that are easy for both respondents and interviewers to understand. Here‚Äôs how to ensure your surveys are clear, efficient, and effective:\n\nUse Simple, Clear Language\nWhen designing your survey, make sure the questions are easy to understand. Avoid technical jargon or complex wording. The simpler your questions, the more accurate your data will be.\nExample: Instead of asking, ‚ÄúWhat is your frequency of maize consumption in a bi-weekly period?‚Äù, you can ask, ‚ÄúHow often do you eat maize in two weeks?‚Äù This reduces confusion and ensures respondents provide the correct answers.\nChoose the Right Question Types\nKoboToolbox offers a variety of question types, such as multiple-choice, single-choice, and text answers. Choose the type that best fits the information you need:\n\nSingle-choice for questions with one possible answer (e.g., ‚ÄúWhat is your gender?‚Äù).\nMultiple-choice for questions where more than one answer is possible (e.g., ‚ÄúWhich of the following crops do you grow?‚Äù).\nText input for open-ended questions (e.g., ‚ÄúPlease describe the challenges you face in farming.‚Äù).\n\nExample: When conducting a household survey, you might ask:\n\n‚ÄúWhat is your source of drinking water?‚Äù (Single choice: river, well, tap water)\n‚ÄúWhat sanitation facilities do you use?‚Äù (Multiple choice: pit latrine, flush toilet, none)\n\nUse Skip Logic for Relevant Questions\nSkip logic helps guide respondents to relevant questions based on their previous answers. This saves time and ensures respondents only answer questions that apply to them.\nExample: If you ask, ‚ÄúDo you own a mobile phone?‚Äù and the respondent answers ‚ÄúNo,‚Äù skip the following questions about phone usage and move directly to the next relevant section.\nTest Your Survey Before Deployment\nBefore deploying your survey to the field, always test it. KoboToolbox lets you preview the survey, so you can see how the questions flow and identify any issues with wording, skip logic, or design.\nExample: You can test a health survey by filling out the questions yourself or with colleagues to ensure everything functions smoothly. This way, you catch any problems early, like a question not appearing at the right time.\n\n\n\nBest Practices for Managing CAPI Teams Using KoboToolbox\nWhen you‚Äôre working with a field team to collect data using KoboToolbox, it‚Äôs essential to ensure that everyone is organized and on the same page. Effective management leads to smoother data collection and higher quality results.\n\nTrain Your Team on KoboToolbox\nBefore your team heads into the field, make sure everyone understands how to use KoboCollect (the mobile app) and the survey itself. Provide hands-on training, including how to download and sync surveys, enter responses, and handle common issues.\nExample: If you‚Äôre conducting a baseline survey in a rural community, walk your team through using the app offline. This way, when they are in areas with no internet, they‚Äôll know how to collect data without problems and upload it when they return to base.\nAssign Clear Roles and Responsibilities\nDivide tasks among your team members to avoid confusion. Have specific people responsible for technical support, others for managing data quality, and the rest for conducting interviews.\nExample: If you have a team of 10, designate one or two people as ‚Äúdata quality checkers‚Äù who review incoming data each day, while the remaining team members focus on conducting interviews and syncing responses.\nSet Realistic Daily Targets\nEnsure your team has a clear goal for the number of interviews they should complete each day. This helps keep everyone motivated and ensures you collect enough data on time.\nExample: If your project requires 500 responses in 5 days, divide this among the team so each member knows their target. For a team of 10, this means completing 10 interviews per person per day.\nMonitor Data Quality in Real-Time\nOne of the advantages of KoboToolbox is that it allows you to monitor data as it‚Äôs being collected. Regularly check incoming data for consistency and completeness. If there are any errors, you can address them before the team finishes the fieldwork.\nExample: If you notice that certain responses are missing or inconsistent (e.g., many participants skipping a particular question), you can inform your team immediately to clarify the questions during interviews.\n\n\n\nOffline CAPI Data Collection: Overcoming Connectivity Challenges with KoboToolbox\nCollecting data in areas with poor or no internet connection can be challenging. Fortunately, KoboToolbox is built for these environments. Here‚Äôs how to make the most of its offline capabilities:\n\nDownload Surveys in Advance\nBefore heading into the field, ensure that your team has downloaded the survey to their mobile devices. KoboCollect stores the surveys locally, so they can be accessed without an internet connection.\nExample: If you‚Äôre working in remote villages in Kenya, your team can download the surveys while they still have internet access at the office or in town. Once they reach the field, they can continue interviewing participants without needing Wi-Fi or mobile data.\nCollect Data Offline and Sync Later\nDuring interviews, KoboCollect will save all the responses on the device. When your team returns to an area with internet, they can upload all the data to the KoboToolbox server with one click.\nExample: After a long day of interviewing farmers about their crop yields, your team gets back to the office where there‚Äôs Wi-Fi. They sync their devices, and all the data is uploaded to the server without any issues.\nPlan for Backup Power\nIn remote areas, battery life is a big concern. Ensure your team has portable chargers or backup power sources to keep their devices running throughout the day.\nExample: If your team is surveying in a rural area where electricity is unreliable, equip them with power banks to keep their devices charged. This way, they can keep collecting data without interruption."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "",
    "text": "Cover picture courtesy of Blessman International"
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#variable-definitions",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#variable-definitions",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "1. Variable Definitions",
    "text": "1. Variable Definitions\nIn designing the evaluation framework for the School Feeding Program (SFP), it is essential to define variables that align with the program‚Äôs goals and context. Below, we outline the variables categorized into Outcome Variables, Control Variables, and Other Variables, ensuring they mirror the structure of a health program evaluation dataset.\n\nOutcome Variable\nThis variable measures the primary goal of the SFP: improving school attendance.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nattendance_rate\nAverage student attendance rate per school term (percent)\n\n\n\n\n\nControl Variables\nThese variables account for household and socio-economic factors that might influence school attendance or participation in the program.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nage_hh\nAge of the head of the household (in years)\n\n\nage_sp\nAge of the spouse (in years)\n\n\neduc_hh\nEducation of the head of the household (completed years of schooling)\n\n\neduc_sp\nEducation of the spouse (completed years of schooling)\n\n\nfemale_hh\nHead of the household is a woman (0=no, 1=yes)\n\n\nindigenous\nHead of household speaks an indigenous language (0=no, 1=yes)\n\n\nhhsize\nNumber of household members (baseline)\n\n\ndirtfloor\nHome has a dirt floor at baseline (0=no, 1=yes)\n\n\nbathroom\nHome with private bathroom at baseline (0=no, 1=yes)\n\n\nland\nNumber of hectares of land owned by household at baseline\n\n\n\n\n\nOther Variables\nThese variables define the experimental design, program eligibility, and participation details.\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nlocality_identifier\nLocality identifier\n\n\nhousehold_identifier\nUnique household identifier\n\n\ntreatment_locality\nSchool is in a locality with the feeding program (0=no, 1=yes)\n\n\npromotion_locality\nSchool is in a locality where the feeding program was promoted (0=no, 1=yes)\n\n\neligible\nHousehold is eligible for the feeding program (0=no, 1=yes)\n\n\nenrolled\nChild is enrolled in the feeding program (0=no, 1=yes)\n\n\nenrolled_rp\nChild enrolled in the feeding program under the random promotion scenario (0=no, 1=yes)\n\n\npoverty_index\nPoverty Index 1-100\n\n\nround\nSurvey round (0=baseline; 1=follow-up)\n\n\nhospital\nHH member visited hospital in the past year (0=no, 1=yes)\n\n\n\nThis comprehensive set of variables enables a detailed analysis of the program‚Äôs impact while controlling for household-level differences and program design elements. By aligning the variable structure with the program‚Äôs objectives, we can effectively measure the success of the intervention and uncover insights for future implementation."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#causal-inference-and-counterfactuals",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#causal-inference-and-counterfactuals",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "2. Causal Inference and Counterfactuals",
    "text": "2. Causal Inference and Counterfactuals\nCausal inference is the process of determining whether a program or intervention (like the School Feeding Program) directly causes a change in an outcome, such as improved school attendance. It goes beyond simple associations to uncover cause-and-effect relationships by comparing what happened with what could have happened if the program had not been implemented.\nThe idea of counterfactuals lies at the heart of causal inference. A counterfactual refers to the hypothetical scenario of what would have occurred in the absence of the program. Since we cannot observe both the actual outcome and the counterfactual for the same household, researchers rely on rigorous study designs (such as randomized control trials) or statistical techniques to estimate the counterfactual and isolate the program‚Äôs impact.\n\nBefore-After Designs\nThe first ‚Äúexpert‚Äù consultant you hire suggests that to estimate the impact of the School Feeding Program (SFP), you should calculate the change in student attendance rates over time for the schools where households enrolled in the program. The consultant argues that because SFP provides meals that alleviate hunger and improve student focus, any increase in attendance rates over time can be attributed to the program‚Äôs effect.\nUsing the subset of schools in treatment localities, you calculate their average student attendance rates before the implementation of the program and then again two years later. The analysis focuses on comparing the average attendance rates at baseline and follow-up to assess the program‚Äôs impact in villages participating in the School Feeding Program.\n\nm_ba1 &lt;- lm_robust(attendance_rate ~ round, \n                   clusters = locality_identifier,\n                   data = trans_df %&gt;% filter(treatment_locality==1 & enrolled ==1))\n\n\nm_ba2 &lt;- lm_robust(attendance_rate ~ round + age_hh + age_sp + educ_hh + \n                     educ_sp + female_hh + indigenous + hhsize + dirtfloor + \n                     bathroom + land + school_distance, \n                   clusters = locality_identifier,\n                   data = trans_df %&gt;% filter(treatment_locality==1 & enrolled ==1))\n\nt0 &lt;- tbl_regression(m_ba1, intercept = T)\nt01 &lt;- tbl_regression(m_ba2, intercept = T)\n\ntbl_merge_m_ba &lt;-\n  tbl_merge(\n    tbls = list(t0, t01),\n    tab_spanner = c(\"No Controls\", \"With Controls\")\n  )\n\ntbl_merge_m_ba\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNo Controls\n\n\nWith Controls\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n88\n87, 88\n&lt;0.001\n79\n78, 80\n&lt;0.001\n\n\nround\n5.7\n5.3, 6.1\n&lt;0.001\n5.7\n5.3, 6.1\n&lt;0.001\n\n\nage_hh\n\n\n\n\n\n\n-0.05\n-0.07, -0.03\n&lt;0.001\n\n\nage_sp\n\n\n\n\n\n\n0.00\n-0.03, 0.02\n&gt;0.9\n\n\neduc_hh\n\n\n\n\n\n\n-0.05\n-0.11, 0.01\n0.079\n\n\neduc_sp\n\n\n\n\n\n\n0.07\n0.00, 0.13\n0.038\n\n\nfemale_hh\n\n\n\n\n\n\n-0.86\n-1.4, -0.28\n0.004\n\n\nindigenous\n\n\n\n\n\n\n1.7\n1.3, 2.1\n&lt;0.001\n\n\nhhsize\n\n\n\n\n\n\n1.5\n1.5, 1.6\n&lt;0.001\n\n\ndirtfloor\n\n\n\n\n\n\n2.0\n1.7, 2.3\n&lt;0.001\n\n\nbathroom\n\n\n\n\n\n\n-0.31\n-0.60, -0.02\n0.039\n\n\nland\n\n\n\n\n\n\n-0.08\n-0.13, -0.04\n&lt;0.001\n\n\nschool_distance\n\n\n\n\n\n\n0.00\n0.00, 0.01\n0.14\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nDoes the before-and-after comparison control for all the factors that affect student attendance over time?\nNo, it is unlikely that this analysis accounts for all the factors influencing attendance. For instance, there could be other educational or health-related interventions occurring simultaneously in the communities receiving the School Feeding Program (SFP), which might also contribute to changes in attendance. Additionally, external factors like a regional economic crisis or natural disasters could have independently affected attendance. In the absence of SFP, attendance might have increased or decreased due to these factors, making it challenging to attribute all observed changes solely to the program.\nBased on these results produced by the before-and-after analysis, should SFP be scaled up nationally?\nNo, based on the current results, scaling up the program nationally might not be justified yet. While the School Feeding Program appears to have improved average attendance rates, the increase of 5.7 percentage points may not be sufficient to meet the government‚Äôs threshold for program effectiveness. Moreover, without understanding the contribution of confounding factors, it remains unclear whether the observed improvements are entirely due to the program.\n\n\nEnrolled vs.¬†Non-Enrolled\nAnother consultant proposes a different approach, suggesting it would be more appropriate to estimate the counterfactual in the post-intervention period, two years after the program‚Äôs start. The consultant correctly notes that of the 5,929 households in the baseline sample, only 2,907 enrolled in the School Feeding Program (SFP), leaving approximately 51 percent of households without access to SFP.\nThe consultant argues that all schools within the 100 pilot villages were eligible to enroll in the program, with households in these communities sharing similar characteristics. For example, households rely on comparable school infrastructures, face similar regional conditions, and have children subject to the same school policies. Furthermore, economic activities and living standards within these localities are generally uniform.\nThe consultant asserts that under such circumstances, attendance rates for households not enrolled in SFP after the intervention can reasonably estimate the counterfactual outcomes for those enrolled. Consequently, you decide to compare average student attendance rates in the post-intervention period for both groups‚Äîschools participating in the School Feeding Program and those that opted out.\n\nm_ene1 &lt;- lm_robust(attendance_rate ~ enrolled, \n                    clusters = locality_identifier,\n                    data = trans_df %&gt;% filter(treatment_locality==1 & round ==1))\n\nm_ene2 &lt;- lm_robust(attendance_rate ~ enrolled + age_hh + age_sp + educ_hh + \n                      educ_sp + female_hh + indigenous + hhsize + dirtfloor + \n                      bathroom + land + school_distance, \n                    clusters = locality_identifier,\n                    data = trans_df %&gt;% filter(treatment_locality==1 & round ==1))\n\nt0a &lt;- tbl_regression(m_ene1, intercept = T)\nt0a1 &lt;- tbl_regression(m_ene2, intercept = T)\n\ntbl_merge_m_ene &lt;-\n  tbl_merge(\n    tbls = list(t0a, t0a1),\n    tab_spanner = c(\"No Controls\", \"With Controls\")\n  )\n\ntbl_merge_m_ene\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNo Controls\n\n\nWith Controls\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n81\n80, 81\n&lt;0.001\n74\n72, 76\n&lt;0.001\n\n\nenrolled\n12\n12, 13\n&lt;0.001\n8.5\n8.0, 9.1\n&lt;0.001\n\n\nage_hh\n\n\n\n\n\n\n-0.08\n-0.12, -0.04\n&lt;0.001\n\n\nage_sp\n\n\n\n\n\n\n0.04\n0.00, 0.09\n0.045\n\n\neduc_hh\n\n\n\n\n\n\n0.04\n-0.06, 0.14\n0.5\n\n\neduc_sp\n\n\n\n\n\n\n0.10\n-0.02, 0.22\n0.088\n\n\nfemale_hh\n\n\n\n\n\n\n-0.50\n-1.6, 0.58\n0.4\n\n\nindigenous\n\n\n\n\n\n\n1.7\n0.84, 2.5\n&lt;0.001\n\n\nhhsize\n\n\n\n\n\n\n1.7\n1.6, 1.8\n&lt;0.001\n\n\ndirtfloor\n\n\n\n\n\n\n1.7\n1.2, 2.3\n&lt;0.001\n\n\nbathroom\n\n\n\n\n\n\n-0.53\n-1.1, 0.00\n0.052\n\n\nland\n\n\n\n\n\n\n0.01\n-0.09, 0.11\n0.8\n\n\nschool_distance\n\n\n\n\n\n\n0.01\n-0.01, 0.02\n0.3\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nDoes this analysis likely control for all the factors that determine differences in student attendance between the enrolled and non-enrolled groups?\nNo, it is unlikely that the multivariate analysis fully controls for all the factors that influence the difference in attendance rates between the two groups. There could be unobservable factors that contribute to why some schools enroll in the feeding program while others do not. For instance, household preferences, school engagement levels, or the motivation of parents could play a role in determining which schools opt for the program. These factors may not be fully captured in the analysis.\nBased on these results produced by the enrolled vs.¬†non-enrolled method, should the School Feeding Program (SFP) be scaled up nationally?\nBased strictly on the estimate from the multivariate linear regression, the SFP should not be scaled up nationally based on the findings here. The program increased average student attendance by 8.5%, which is a positive but modest improvement. While this result is statistically significant (p-value &lt; 0.001), it is lower than the expected national threshold improvement in attendance, suggesting that scaling up the program may not immediately achieve the desired outcomes at a larger scale. However, the modest effect size means that further investigation into the program‚Äôs impact across different contexts and regions is necessary to determine if it could contribute meaningfully to national efforts in improving student attendance."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#randomized-assignment",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#randomized-assignment",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "3. Randomized Assignment",
    "text": "3. Randomized Assignment\nRandom Assignment in the context of our school feeding program evaluation means that households or communities are randomly assigned to either the treatment group (where they receive the feeding program) or the control group (where they do not). This random assignment ensures that every participant has an equal chance of being placed in either group, making it more likely that the groups are similar at the start of the study. As a result, any differences in outcomes, such as changes in children‚Äôs health or learning outcomes, can be attributed to the school feeding program itself, rather than other external factors. This method strengthens the validity of our findings and helps ensure that the observed impacts are genuinely due to the program intervention.\nThe key is to find a group of villages that are very similar to the 100 treatment villages, except for the fact that one group participated in the school feeding program and the other did not. Since the treatment villages were randomly selected from the pool of rural villages, they should, on average, have similar characteristics to those villages that did not participate in the program.\nTo improve the counterfactual estimate, we utilize an additional 100 rural villages that were not part of the feeding program. These comparison villages were also randomly selected, ensuring that they share similar characteristics with the treatment villages at the outset of the program. The random assignment of the program ensures that any differences in outcomes (e.g., improvements in children‚Äôs nutrition or learning) between the treatment and comparison villages can be attributed to the program, not external factors.\nTo validate this assumption, we would need to test whether the characteristics of eligible households in both the treatment and comparison villages were similar at the baseline, ensuring that no major differences existed before the program began. If the characteristics are similar, it further supports the idea that the program‚Äôs effects are due to the intervention itself rather than other external factors.\n\ndf_elig &lt;- trans_df %&gt;%\n  filter(eligible == 1) \n\ndf_elig %&gt;% \n  filter(round == 0) %&gt;%\n  dplyr::select(treatment_locality, locality_identifier,\n                age_hh, age_sp, educ_hh, educ_sp, female_hh, indigenous, \n                hhsize, dirtfloor, bathroom, land, school_distance) %&gt;%\n  tidyr::pivot_longer(-c(\"treatment_locality\",\"locality_identifier\")) %&gt;%\n  group_by(name) %&gt;%\n  do(tidy(lm_robust(value ~ treatment_locality, data = .))) %&gt;%\n  filter(term == \"treatment_locality\") %&gt;%\n  dplyr::select(name, estimate, std.error, p.value) %&gt;%\n  kable()\n\n\n\n\nname\nestimate\nstd.error\np.value\n\n\n\n\nage_hh\n-0.6354625\n0.3759583\n0.0910361\n\n\nage_sp\n-0.0386302\n0.3120790\n0.9014911\n\n\nbathroom\n0.0149907\n0.0132340\n0.2573724\n\n\ndirtfloor\n-0.0129497\n0.0118744\n0.2755159\n\n\neduc_hh\n0.1607976\n0.0697576\n0.0211978\n\n\neduc_sp\n0.0289107\n0.0670018\n0.6661273\n\n\nfemale_hh\n-0.0041155\n0.0070493\n0.5593691\n\n\nhhsize\n0.0596953\n0.0530454\n0.2604833\n\n\nindigenous\n0.0091048\n0.0131969\n0.4902756\n\n\nland\n-0.0402168\n0.0704607\n0.5681787\n\n\nschool_distance\n2.9087631\n1.1323148\n0.0102288\n\n\n\n\n\nThe average characteristics of households in both the treatment and comparison villages appear very similar. Among the various variables tested, the only statistically significant differences are in the number of years of education of the head of household and the distance to the nearest school, which are relatively small in magnitude. Specifically, the difference in the education of the household head is 0.16 years (which is less than 6% of the average years of education in the comparison group), and the difference in the distance to school is 2.91 kilometers (less than 3% of the comparison group‚Äôs average distance). These differences are statistically significant, but small, indicating that the two groups are quite similar in terms of key demographic factors.\nEven in a randomized experiment involving a large sample, small differences can occur by chance due to the nature of statistical tests. In fact, using a typical 5% significance level, we would expect some differences in around 5% of the characteristics simply due to random variability. Therefore, although small statistically significant differences exist, the overall similarity between the two groups suggests that the random assignment was effective and that the treatment and comparison groups are comparable for the evaluation of the feeding program‚Äôs impact.\nEstimate the average attendance rate for eligible households in the treatment and comparison villages for each period. What is the impact of the program?\n\nout_round0 &lt;- lm_robust(attendance_rate ~ treatment_locality,\n                        data = df_elig %&gt;% filter(round == 0),\n                        clusters = locality_identifier)\nout_round1 &lt;- lm_robust(attendance_rate ~ treatment_locality,\n                        data = df_elig %&gt;% filter(round == 1),\n                        clusters = locality_identifier)\n\nt0b &lt;- tbl_regression(out_round0, intercept = T)\nt0b1 &lt;- tbl_regression(out_round1, intercept = T)\n\ntbl_merge_m_ba1 &lt;-\n  tbl_merge(\n    tbls = list(t0b, t0b1),\n    tab_spanner = c(\"Baseline\", \"Follow Up\")\n  )\n\ntbl_merge_m_ba1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nBaseline\n\n\nFollow Up\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n88\n87, 88\n&lt;0.001\n85\n84, 85\n&lt;0.001\n\n\ntreatment_locality\n0.07\n-0.29, 0.44\n0.7\n8.7\n8.0, 9.4\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nAt baseline, there is no statistically significant difference in the average characteristics between the treatment and comparison groups. This confirms that the groups are similar, as expected under randomized assignment. The baseline results show that the treatment locality (the area receiving the feeding program) does not significantly differ from the comparison group in terms of the outcome measure (Beta = 0.07, p-value = 0.7).\nAt follow-up, however, the treatment locality shows a statistically significant and positive effect on the outcome measure, with a beta coefficient of 8.7 (p-value &lt; 0.001). This indicates that households in the treatment locality saw a notable improvement compared to those in the comparison villages. Specifically, the intervention appears to have resulted in an increase in the outcome, possibly reflecting the positive effects of the feeding program, given the substantial change in the beta coefficient.\nThe impact of the program is therefore evident in the follow-up period, and the reduction in the treatment and comparison villages‚Äô differences shows a clear program effect, with an estimated increase of 8.7 units on the attendance rate, which is statistically significant.\nThus, these findings support the conclusion that the feeding program had a positive impact on the target population over the course of the study period.\nRe-estimate using a multivariate regression analysis that controls for the other observable characteristics of the sample households. How does your impact estimate change?\n\nout_round1_nocov &lt;- lm_robust(attendance_rate ~ treatment_locality,\n                              data = df_elig %&gt;% filter(round == 1),\n                              clusters = locality_identifier)\nout_round1_wcov &lt;- lm_robust(attendance_rate ~ treatment_locality +\n                               age_hh + age_sp + educ_hh + educ_sp + \n                               female_hh + indigenous + hhsize + dirtfloor + \n                               bathroom + land + school_distance,\n                             data = df_elig %&gt;% filter(round == 1),\n                             clusters = locality_identifier)\nt2 &lt;- tbl_regression(out_round1_nocov, intercept = T)\nt3 &lt;- tbl_regression(out_round1_wcov, intercept = T)\n\ntbl_merge_out_round1 &lt;-\n  tbl_merge(\n    tbls = list(t2, t3),\n    tab_spanner = c(\"**No Covariate Adjust.**\", \"**With Covariate Adjust.**\")\n  )\n\ntbl_merge_out_round1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNo Covariate Adjust.\n\n\nWith Covariate Adjust.\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n85\n84, 85\n&lt;0.001\n76\n75, 78\n&lt;0.001\n\n\ntreatment_locality\n8.7\n8.0, 9.4\n&lt;0.001\n8.6\n8.0, 9.2\n&lt;0.001\n\n\nage_hh\n\n\n\n\n\n\n-0.04\n-0.06, -0.01\n0.006\n\n\nage_sp\n\n\n\n\n\n\n0.00\n-0.03, 0.03\n0.9\n\n\neduc_hh\n\n\n\n\n\n\n0.03\n-0.05, 0.11\n0.4\n\n\neduc_sp\n\n\n\n\n\n\n0.02\n-0.06, 0.10\n0.7\n\n\nfemale_hh\n\n\n\n\n\n\n-0.55\n-1.3, 0.21\n0.2\n\n\nindigenous\n\n\n\n\n\n\n1.6\n1.0, 2.2\n&lt;0.001\n\n\nhhsize\n\n\n\n\n\n\n1.4\n1.3, 1.5\n&lt;0.001\n\n\ndirtfloor\n\n\n\n\n\n\n1.6\n1.1, 2.1\n&lt;0.001\n\n\nbathroom\n\n\n\n\n\n\n-0.24\n-0.67, 0.18\n0.3\n\n\nland\n\n\n\n\n\n\n-0.03\n-0.10, 0.03\n0.3\n\n\nschool_distance\n\n\n\n\n\n\n0.00\n-0.01, 0.01\n0.5\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWithout Covariate Adjustment:\nAt the baseline, the coefficient for the treatment locality is 8.7 (with a 95% confidence interval of 8.0 to 9.4), which is statistically significant (p-value &lt; 0.001). This suggests that, without adjusting for other factors, the households in the treatment locality (those receiving the feeding program) exhibit a significant improvement compared to those in the comparison group.\nWith Covariate Adjustment:\nWhen adjusting for other observable characteristics such as age, education, and household size, the coefficient for the treatment locality is slightly reduced to 8.6 (95% CI: 8.0 to 9.2) but remains statistically significant (p-value &lt; 0.001). This indicates that even when accounting for factors like age, education, and household characteristics, the treatment locality still shows a strong and positive effect, with the intervention leading to a substantial improvement in the outcome measure.\n\nWhy is the Impact Estimate Unchanged with Covariate Adjustment?\nThe treatment effect remains nearly unchanged when controlling for additional factors because of the randomized assignment. Randomization ensures that the treatment and comparison groups are very similar in characteristics at baseline, and external factors affecting the outcome should affect both groups equally over time. Therefore, any changes observed in the treatment locality compared to the comparison group can confidently be attributed to the feeding program rather than differences in baseline characteristics or external influences.\n\n\nConclusion on the Program‚Äôs Impact\nGiven that the estimated impact remains consistent even after controlling for additional characteristics, it is clear that the feeding program has a significant positive effect on the target population. The treatment group shows a noticeable improvement in outcomes, and this improvement is robust to covariate adjustments.\n\n\nShould the Feeding Program Be Scaled Up?\nYes, the feeding program should be scaled up. The impact on the outcome measure is statistically significant and substantial. The effect of the intervention, even after accounting for other factors, supports the case for expanding the program to other regions to improve the well-being of households in similar circumstances."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#instrumental-variables",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#instrumental-variables",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "4. Instrumental Variables",
    "text": "4. Instrumental Variables\nInstrumental Variables in the context of our school feeding program help us figure out how the program affects attendance rates when other factors might confuse the results. An instrumental variable is something that influences whether a child participates in the program (like whether their school is in a treatment area) but doesn‚Äôt directly impact attendance rates except through the program itself. This approach helps isolate the program‚Äôs true effect on attendance, even if there are other overlapping influences.\nLet us now try using the randomized promotion method to evaluate the impact of the school feeding program (SFP) on attendance rates. Imagine the Ministry of Education decides that the feeding program should eventually be made available to all schools nationwide. This is a different situation from the randomized assignment design we‚Äôve considered so far. However, given the logistical realities of scaling the program, you propose an incremental rollout.\nTo assess its impact, you randomly select a subset of schools (indicated by promotion_locality) to receive an intensive promotion campaign aimed at increasing awareness and participation in the feeding program. This campaign includes activities such as community outreach, parent meetings, and tailored communication materials to emphasize the program‚Äôs benefits. Importantly, the promotion focuses solely on raising awareness and boosting program enrollment, ensuring it does not directly encourage unrelated behaviors that could influence attendance rates. This design ensures the promotion can be used as a valid instrumental variable (IV) for understanding how the feeding program affects attendance rates.\nWhat was the effect of the promotion campaign upon enrollment?\nNote you should use the variable enrolled_rp¬†for this question\n\nm_enroll &lt;- lm_robust(enrolled_rp ~ promotion_locality,\n                      clusters = locality_identifier,\n                      data = trans_df %&gt;% filter(round == 1))\n\nt_enroll &lt;- tbl_regression(m_enroll, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\nt_enroll\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n0.08\n0.04, 0.13\n0.001\n    promotion_locality\n0.41\n0.34, 0.48\n&lt;0.001\n  \n  \n    \n      Adjusted R¬≤ = 0.200; R¬≤ = 0.200; No. Obs. = 9,914\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nAfter two years of promotion and program implementation, you find that 41% of students in schools randomly assigned to the promotion campaign are attending school more regularly, compared to only 8% in non-promoted schools.\nBecause the promoted and non-promoted schools were assigned at random, we can confidently assume that the baseline characteristics of the two groups were similar in the absence of the promotion. This assumption is validated by comparing baseline attendance rates and other school-related characteristics, which showed no significant differences.\nFrom the results in Table 2, the estimated impact of the promotion locality on attendance rates is a significant increase of 41 percentage points (Beta = 0.41, 95% CI [0.34, 0.48], p &lt; 0.001). The intercept (baseline attendance rate in non-promoted schools) was estimated at 8% (Beta = 0.08, 95% CI [0.04, 0.13], p = 0.001). The model explains 20% of the variation in attendance rates (Adjusted R¬≤ = 0.20), indicating a strong relationship between promotion and improved attendance outcomes.\nCompare baseline attendance rates based upon assignment to promotion.\n\nm_base_attend &lt;- lm_robust(attendance_rate ~ promotion_locality,\n                           clusters = locality_identifier,\n                           data = trans_df %&gt;% filter(round == 0)\n)\n\nt_base_attend &lt;- tbl_regression(m_base_attend, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  ) \nt_base_attend\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n85\n85, 86\n&lt;0.001\n    promotion_locality\n0.05\n-0.44, 0.53\n0.9\n  \n  \n    \n      Adjusted R¬≤ = 0.000; R¬≤ = 0.000; No. Obs. = 9,913\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nEstimate the difference in attendance rates by assignment to promotion, in the post-treatment period\n\nm_post_attend &lt;- lm_robust(attendance_rate ~ promotion_locality,\n                           clusters = locality_identifier,\n                           data = trans_df %&gt;% filter(round == 1)\n)\n\nt_post_attend &lt;- tbl_regression(m_post_attend, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  ) \nt_post_attend\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n84\n83, 85\n&lt;0.001\n    promotion_locality\n3.3\n2.2, 4.4\n&lt;0.001\n  \n  \n    \n      Adjusted R¬≤ = 0.026; R¬≤ = 0.027; No. Obs. = 9,914\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nUsing this attendance rate estimate and the estimated proportion of ‚Äúcompliers‚Äù, estimate the LATE/CACE\n\nLATE (Local Average Treatment Effect):\nLATE measures the effect of the program only on the group that complied with the treatment assignment (e.g., those who were offered the feeding program and actually participated). It tells us the impact on attendance rates for these participants, not for everyone assigned to the treatment or control groups.\n\n\nCACE (Complier Average Causal Effect):\nCACE is essentially the same as LATE in many contexts, particularly in randomized trials. It focuses on estimating the causal effect of the program for those who adhered to their assignment (e.g., those who were assigned to the treatment and participated, or those in the control who did not access the treatment).\n\nm_cace &lt;- iv_robust(attendance_rate ~ enrolled_rp |\n                      promotion_locality,\n                    clusters = locality_identifier,\n                    data = trans_df %&gt;% filter(round == 1))\n\nm_cace_wcov &lt;- iv_robust(attendance_rate ~ enrolled_rp + \n                           age_hh + age_sp + educ_hh + educ_sp + \n                           female_hh + indigenous + hhsize + dirtfloor + \n                           bathroom + land + school_distance | \n                           promotion_locality + \n                           age_hh + age_sp + educ_hh + educ_sp + \n                           female_hh + indigenous + hhsize + dirtfloor + \n                           bathroom + land + school_distance ,\n                         clusters = locality_identifier,\n                         data = trans_df %&gt;% filter(round == 1))\n\n\nt_cace &lt;- tbl_regression(m_cace, intercept = T)\nt_cace_wcov &lt;- tbl_regression(m_cace_wcov, intercept = T)\n\ntbl_merge_cace &lt;-\n  tbl_merge(\n    tbls = list(t_cace, t_cace_wcov),\n    tab_spanner = c(\"**No Covariate Adjust.**\", \"**With Covariate Adjust.**\")\n  )\n\ntbl_merge_cace\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nNo Covariate Adjust.\n\n\nWith Covariate Adjust.\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n83\n82, 84\n&lt;0.001\n75\n74, 76\n&lt;0.001\n\n\nenrolled_rp\n8.1\n6.2, 10\n&lt;0.001\n8.3\n6.7, 10\n&lt;0.001\n\n\nage_hh\n\n\n\n\n\n\n-0.06\n-0.09, -0.04\n&lt;0.001\n\n\nage_sp\n\n\n\n\n\n\n0.01\n-0.02, 0.04\n0.4\n\n\neduc_hh\n\n\n\n\n\n\n-0.03\n-0.11, 0.04\n0.4\n\n\neduc_sp\n\n\n\n\n\n\n0.04\n-0.04, 0.12\n0.4\n\n\nfemale_hh\n\n\n\n\n\n\n-0.88\n-1.7, -0.11\n0.025\n\n\nindigenous\n\n\n\n\n\n\n2.0\n1.3, 2.7\n&lt;0.001\n\n\nhhsize\n\n\n\n\n\n\n1.7\n1.6, 1.9\n&lt;0.001\n\n\ndirtfloor\n\n\n\n\n\n\n1.8\n1.3, 2.3\n&lt;0.001\n\n\nbathroom\n\n\n\n\n\n\n-0.59\n-1.0, -0.18\n0.005\n\n\nland\n\n\n\n\n\n\n-0.08\n-0.16, 0.00\n0.039\n\n\nschool_distance\n\n\n\n\n\n\n0.00\n0.00, 0.01\n0.3\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nCompare baseline attendance rates based upon assignment to promotion\nThe baseline attendance rates show that there is no significant difference in attendance rates between schools assigned to the promotion (SFP) and those that were not, as indicated by the promotion locality coefficient of 0.05 with a 95% Confidence Interval (CI) of [-0.44, 0.53] and a p-value of 0.9. The p-value is greater than the 0.05 significance level, which means that any differences in baseline attendance are likely due to random variation, not the promotion itself.\nEstimate the difference in attendance rates by assignment to promotion, in the post-treatment period\nThe post attendance period shows a significant positive effect on attendance, with a coefficient of 3.3 (95% CI [2.2, 4.4], p-value &lt; 0.001). This suggests that schools assigned to the feeding program promotion saw an increase in attendance rates by about 3.3 percentage points compared to non-promoted schools. The model‚Äôs adjusted R¬≤ of 0.026 indicates that a small proportion of the variation in attendance is explained by the promotion, but the effect is still statistically significant.\nUsing this attendance rate estimate and the estimated proportion of ‚Äúcompliers,‚Äù estimate the LATE/CACE\nThe Local Average Treatment Effect (LATE) and the Complier Average Causal Effect (CACE) are estimated by considering both unadjusted and adjusted models.\nNo Covariate Adjustment: The coefficient for the promotion locality remains significant (Beta = 8.1, 95% CI [6.2, 10], p-value &lt; 0.001), suggesting that, on average, the promotion led to an 8.1 percentage point increase in attendance for those schools in the promotion locality who complied with the program.\nWith Covariate Adjustment: After adjusting for covariates such as household characteristics and school factors, the effect is slightly higher (Beta = 8.3, 95% CI [6.7, 10], p-value &lt; 0.001), reinforcing the robustness of the promotion‚Äôs impact. These results suggest that the school feeding program had a substantial positive impact on attendance rates, particularly for the compliers‚Äîthose schools that adhered to the promotion. The covariate-adjusted estimates provide additional confidence that the observed effect is not solely driven by confounding factors.\nWhat are the key conditions for accepting the results from the randomized promotion evaluation of the SFP\n\nBaseline Equivalence: The schools in the promoted and non-promoted groups should have similar characteristics before the promotion. The baseline attendance rates in the first table show no significant difference, suggesting this assumption holds true.\nPromotion Effectiveness: The promotion should effectively increase school attendance. This assumption holds in the post-treatment period, where the promoted schools show a significant increase in attendance by 3.3 percentage points.\nNo Direct Effects on Other Factors: The promotion should only affect attendance and not other outcomes (such as student performance or health). This assumption cannot be directly tested but is informed by the program‚Äôs design focusing only on increasing school attendance.\n\nShould the SFP be Scaled Up Nationally?\nBased on the results from the regression analysis, the school feeding program shows a significant positive impact on attendance rates. The estimated LATE/CACE of 8.3 percentage points suggests a clear benefit from the program. Therefore, the results support scaling the program up nationally, as the program‚Äôs effectiveness in improving attendance is statistically significant and substantial."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#regression-discontinuity-designs",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#regression-discontinuity-designs",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "5. Regression Discontinuity Designs",
    "text": "5. Regression Discontinuity Designs\nRegression Discontinuity Designs (RDD) are a method used to evaluate the impact of a treatment or intervention by focusing on cases where a specific cutoff or threshold determines who receives the treatment. For example, imagine a school program that only allows students with test scores above a certain level to participate. RDD compares students who are just above the threshold (and get the program) with those who are just below it (and don‚Äôt get the program). This helps estimate the effect of the program by assuming that those on either side of the cutoff are very similar, except for receiving the program.\nIn simple terms, RDD looks at situations where a rule or score divides people into different groups and then compares those on either side of that line to see if the treatment makes a real difference.\n\nApplication\nNow consider how the regression discontinuity design (RDD) method can be applied to our School Feeding Program (SFP). After doing some more investigation into the design of SFP, you find that in addition to randomly selecting treatment villages, the authorities targeted the program to low-income households using the national poverty line. The poverty line is based on a poverty index that assigns each household in the country a score between 20 and 100 based on its assets, housing conditions, and socio demographic structure. The poverty line has been officially set at 58. This means that all households with a score of 58 or below are classified as poor, and all households with a score of more than 58 are considered to be non-poor. Even in the treatment villages, only poor households are eligible to enroll in SFP. Your data set includes information on both poor and non-poor households in the treatment villages\n\n# Create data subset with only treatment localities\ndf_treat &lt;- trans_df %&gt;%\n  filter(treatment_locality == 1)\n\nBefore carrying out the regression discontinuity design estimations, you decide to check whether there is any evidence of manipulation of the eligibility index. As a first step, you check whether the density of the eligibility index raises any concerns about manipulation of the index. You plot the percentage of schools against the baseline poverty index.\n\nggplot(df_treat, aes(x = poverty_index)) +\n  geom_vline(xintercept = 58) +\n  geom_density() +\n  labs(x = \"Poverty Index\")\n\n\n\n\n\n\n\n\nWe can also conduct a McCrary density test, to examine this more formally.\n\ntest_density &lt;- rdplotdensity(rdd = rddensity(df_treat$poverty_index, c = 58), \n                              X = df_treat$poverty_index, \n                              type = \"both\")\n\n\n\n\n\n\n\n\nThe figures do not indicate any clustering of schools right below the cutoff of 58.\nNext, you check whether households respected their assignment to the treatment and comparison groups on the basis of their eligibility score. You plot participation in the program against the baseline poverty index and find that two years after the start of the pilot, only households with a score of 58 or below (that is, to the left of the poverty line) have been allowed to enroll in SFP. In addition, all of the eligible households enrolled in SFP. In other words, you find full compliance and have a ‚Äúsharp‚Äù RDD.\n\nggplot(df_treat, aes(y = enrolled, x = poverty_index)) +\n  geom_vline(xintercept = 58) +\n  geom_point() +\n  labs(x = \"Poverty Index\", y = \"Enrolled\")\n\n\n\n\n\n\n\n\nYou now proceed to apply the RDD method to compute the impact of the program. Using follow-up data, you again plot the relationship between the scores on the poverty index and predicted attendance rates and find the relation illustrated in the figure below. In the relationship between the poverty index and the predicted attendance rates, you find a clear break, or discontinuity, at the poverty line (58).\n\ndf_treat %&gt;%\n  filter(round == 1) %&gt;%\n  mutate(enrolled_lab = ifelse(enrolled == 1, \"Enrolled\", \"Not Enrolled\")) %&gt;%\n  ggplot(aes(x = poverty_index, y = attendance_rate,\n             group = enrolled_lab, colour = enrolled_lab, fill = enrolled_lab)) +\n  geom_point(alpha = 0.03) +\n  geom_smooth(method = \"lm\") +\n  labs(x = \"Poverty Index\", y = \"Attendance_rate\") +\n  scale_colour_viridis_d(\"Enrollment:\", end = 0.7) +\n  scale_fill_viridis_d(\"Enrollment:\", end = 0.7) +\n  theme(legend.position=\"bottom\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe discontinuity reflects an increase in attendance rates for those schools eligible to receive the program. Given that schools on both sides of the cutoff score of 58 are very similar, the plausible explanation for the different level of attendance rates is that one group of schools was eligible to enroll in the program and the other was not. You estimate this difference through a regression with the findings shown in the following table.\n\ndf_treat &lt;- df_treat %&gt;%\n  mutate(poverty_index_c0 = poverty_index - 58)\n\nout_rdd &lt;- lm_robust(attendance_rate ~ poverty_index_c0 * enrolled + \n                       age_hh + age_sp + educ_hh + educ_sp + \n                       female_hh + indigenous + hhsize + dirtfloor + \n                       bathroom + land + school_distance,\n                     data = df_treat %&gt;% filter(round == 1))\n\ntbl16 &lt;- tbl_regression(out_rdd, intercept = T) %&gt;%\n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\nNote: We could also estimate the effect of the program in the following ways\nEstimating the effect of the program on health expenditures again using regression, but include an interaction with a cubic polynomial of the running variable.\n\nout_rdd_cubic &lt;- lm_robust(attendance_rate ~ enrolled * poverty_index_c0 +\n                             enrolled * I(poverty_index_c0^2) + \n                             enrolled * I(poverty_index_c0^3) +\n                             age_hh + age_sp + educ_hh + educ_sp + \n                             female_hh + indigenous + hhsize + dirtfloor +\n                             bathroom + land + school_distance,\n                           data = df_treat %&gt;% filter(round == 1))\ntbl_cubic &lt;- tbl_regression(out_rdd_cubic, intercept = T) %&gt;% \n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\nEstimating the effect of the program on attendance rates again using regression, but only including observations 5 points above or below the cutoff of 58.\n\nout_rdd5 &lt;- lm_robust(attendance_rate ~ enrolled * poverty_index_c0 + \n                        age_hh + age_sp + educ_hh + educ_sp + \n                        female_hh + indigenous + hhsize + dirtfloor + \n                        bathroom + land + school_distance,\n                      data = df_treat %&gt;% filter(round == 1 &\n                                                   abs(poverty_index_c0) &lt;=5))\n\ntbl_rdd5 &lt;- tbl_regression(out_rdd5, intercept = T) %&gt;% \n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\n\ntbl_merge_rdd_all &lt;-\n  tbl_merge(\n    tbls = list( tbl16,tbl_cubic, tbl_rdd5),\n    tab_spanner = c(\"**Linear**\", \"**Cubic**\", \"**5 Point Window**\")\n  )\n\ntbl_merge_rdd_all\n\n\n\n\n  \n    \n      Characteristic\n      \n        Linear\n      \n      \n        Cubic\n      \n      \n        5 Point Window\n      \n    \n    \n      Beta\n      95% CI1\n      p-value\n      Beta\n      95% CI1\n      p-value\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n75\n73, 77\n&lt;0.001\n75\n73, 77\n&lt;0.001\n75\n72, 77\n&lt;0.001\n    poverty_index_c0\n-0.15\n-0.22, -0.08\n&lt;0.001\n-0.28\n-0.64, 0.08\n0.13\n-0.35\n-0.75, 0.06\n0.094\n    enrolled\n7.7\n7.0, 8.5\n&lt;0.001\n7.6\n6.4, 8.9\n&lt;0.001\n7.3\n5.9, 8.8\n&lt;0.001\n    age_hh\n-0.08\n-0.11, -0.04\n&lt;0.001\n-0.08\n-0.11, -0.04\n&lt;0.001\n-0.05\n-0.10, -0.01\n0.024\n    age_sp\n0.05\n0.01, 0.09\n0.016\n0.05\n0.01, 0.09\n0.016\n0.02\n-0.03, 0.07\n0.5\n    educ_hh\n0.06\n-0.04, 0.16\n0.2\n0.06\n-0.04, 0.16\n0.2\n0.05\n-0.10, 0.21\n0.5\n    educ_sp\n0.12\n0.01, 0.23\n0.034\n0.12\n0.01, 0.23\n0.038\n0.18\n0.01, 0.34\n0.037\n    female_hh\n-0.49\n-1.5, 0.49\n0.3\n-0.48\n-1.5, 0.50\n0.3\n-0.73\n-2.1, 0.65\n0.3\n    indigenous\n1.6\n1.1, 2.1\n&lt;0.001\n1.6\n1.1, 2.1\n&lt;0.001\n1.7\n0.88, 2.6\n&lt;0.001\n    hhsize\n1.7\n1.6, 1.8\n&lt;0.001\n1.7\n1.6, 1.8\n&lt;0.001\n1.7\n1.6, 1.9\n&lt;0.001\n    dirtfloor\n1.5\n0.99, 2.0\n&lt;0.001\n1.5\n1.0, 2.0\n&lt;0.001\n1.6\n0.83, 2.5\n&lt;0.001\n    bathroom\n-0.49\n-0.94, -0.03\n0.036\n-0.49\n-0.95, -0.03\n0.036\n-0.09\n-0.86, 0.68\n0.8\n    land\n0.04\n-0.03, 0.11\n0.3\n0.04\n-0.03, 0.11\n0.2\n0.01\n-0.11, 0.14\n0.8\n    school_distance\n0.00\n0.00, 0.01\n0.11\n0.00\n0.00, 0.01\n0.11\n0.01\n-0.01, 0.02\n0.3\n    poverty_index_c0 * enrolled\n0.17\n0.09, 0.25\n&lt;0.001\n\n\n\n\n\n\n    I(poverty_index_c0^2)\n\n\n\n0.01\n-0.02, 0.04\n0.4\n\n\n\n    I(poverty_index_c0^3)\n\n\n\n0.00\n0.00, 0.00\n0.4\n\n\n\n    enrolled * poverty_index_c0\n\n\n\n0.33\n-0.10, 0.77\n0.13\n0.36\n-0.16, 0.87\n0.2\n    enrolled * I(poverty_index_c0^2)\n\n\n\n-0.01\n-0.05, 0.02\n0.5\n\n\n\n    enrolled * I(poverty_index_c0^3)\n\n\n\n0.00\n0.00, 0.00\n0.6\n\n\n\n  \n  \n    \n      Adjusted R¬≤ = 0.457; R¬≤ = 0.458; No. Obs. = 4,960\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nCombining all these results together we see a consistent effect of the program.\n\n\nResults\nIs the result of the RDD analysis valid for all schools in the program?\nNo, the RDD estimates represent the effects for schools with attendance rates very close to the defined eligibility cutoff. Intuitively, this is the region where schools just eligible for the program and those just ineligible have the most similar baseline characteristics and can be meaningfully compared.\nCompared with the impact estimated with the randomized assignment method, what does this result say about schools with poverty index just below the cutoff?\nThis result indicates that schools with poverty index just below the eligibility threshold experience a smaller increase in attendance rates than the average eligible school. Specifically, schools just under the cutoff score experience an increase of 7.3 percentage points in attendance rates, which is slightly less than the average improvement observed with the randomized assignment method."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#difference-in-differences",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#difference-in-differences",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "6. Difference-in-Differences",
    "text": "6. Difference-in-Differences\nThe Difference-in-Differences (DiD) method is a widely used statistical approach to evaluate the causal effect of an intervention by comparing changes over time between a treatment group and a control group. In our School Feeding Program (SFP), this technique can help us measure how the introduction of the program influenced student attendance rates by comparing schools that implemented the program (treatment group) with those that did not (control group), both before and after the program began.\nThis approach leverages the assumption that, without the intervention, both groups would have followed similar trends over time. By examining the difference in attendance rate changes between these groups, we isolate the program‚Äôs impact while controlling for underlying trends that affect all schools.\nIn this scenario, you have two rounds of data on two groups of schools: one group that enrolled in the program, and another that did not. Remembering the case of the enrolled and non- enrolled groups, you realize that you cannot simply compare the average attendance rates of the two groups because of selection bias. Because you have data for two periods for each school in the sample, you can use those data to solve some of these challenges by comparing the change in attendance rates for the two groups, assuming that the change in the attendance rates of the non-enrolled group reflects what would have happened to the attendance of the enrolled group in the absence of the program. Note that it does not matter which way you calculate the double difference.\n\nout_did &lt;- lm_robust(attendance_rate ~ round * enrolled, \n                     data = trans_df %&gt;% filter(treatment_locality == 1),\n                     clusters = locality_identifier)\n\nout_did_wcov &lt;- lm_robust(attendance_rate ~ round * enrolled +\n                            age_hh + age_sp + educ_hh + educ_sp + \n                            female_hh + indigenous + hhsize + dirtfloor + \n                            bathroom + land + school_distance, \n                          data = trans_df %&gt;% filter(treatment_locality == 1),\n                          clusters = locality_identifier)\n\ntbl_did &lt;- tbl_regression(out_did, intercept = T) %&gt;% \n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\ntbl_did_wcov &lt;- tbl_regression(out_did_wcov, intercept = T) %&gt;% \n  add_glance_source_note(\n    glance_fun = broom::glance, # Extract model summary\n    include = c(\"adj.r.squared\", \"r.squared\", \"nobs\") # Add Adjusted R-squared\n  )\n\n\ntbl_merge_did &lt;-\n  tbl_merge(\n    tbls = list( tbl_did, tbl_did_wcov),\n    tab_spanner = c(\"**No Covariate Adjustment**\", \"**With Covariate Adjustment**\")\n  )\n\ntbl_merge_did\n\n\n\n\n  \n    \n      Characteristic\n      \n        No Covariate Adjustment\n      \n      \n        With Covariate Adjustment\n      \n    \n    \n      Beta\n      95% CI1\n      p-value\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n82\n82, 83\n&lt;0.001\n77\n76, 78\n&lt;0.001\n    round\n-1.3\n-1.9, -0.68\n&lt;0.001\n-1.2\n-1.9, -0.62\n&lt;0.001\n    enrolled\n5.4\n5.1, 5.7\n&lt;0.001\n1.3\n1.1, 1.5\n&lt;0.001\n    round * enrolled\n7.0\n6.4, 7.5\n&lt;0.001\n7.0\n6.4, 7.5\n&lt;0.001\n    age_hh\n\n\n\n-0.07\n-0.09, -0.05\n&lt;0.001\n    age_sp\n\n\n\n0.02\n-0.01, 0.04\n0.14\n    educ_hh\n\n\n\n-0.05\n-0.10, 0.00\n0.046\n    educ_sp\n\n\n\n0.07\n0.01, 0.12\n0.030\n    female_hh\n\n\n\n-0.94\n-1.5, -0.40\n0.001\n    indigenous\n\n\n\n2.0\n1.6, 2.4\n&lt;0.001\n    hhsize\n\n\n\n1.7\n1.6, 1.8\n&lt;0.001\n    dirtfloor\n\n\n\n2.0\n1.7, 2.3\n&lt;0.001\n    bathroom\n\n\n\n-0.43\n-0.70, -0.15\n0.003\n    land\n\n\n\n-0.08\n-0.13, -0.03\n0.004\n    school_distance\n\n\n\n0.00\n0.00, 0.01\n0.3\n  \n  \n    \n      Adjusted R¬≤ = 0.343; R¬≤ = 0.344; No. Obs. = 9,919\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nNext, you estimate the effect using regression analysis. Using a simple linear regression to compute the simple difference-in- differences estimate, you find that the program increased school attendance rate by 7.0. You then refine your analysis by adding additional control variables. In other words, you use a multivariate linear regression that takes into account a host of other factors, and you find the same promotion in school attendance rate.\nWhat are the basic assumptions required to accept this result from difference-in-differences?\nTo accept this result, we assume that there are no differential time varying factors between the two groups other than the program. We assume that the treatment and comparison groups would have equal trends or changes in outcomes in the absence of treatment. While this assumption can‚Äôt be tested in the post intervention period, we can compare trends before the intervention starts.\nBased on the result from difference-in-differences, should HISP be scaled up nationally?\nNo, based on this result, the SFP should not be scaled up nationally because it has Increased by less than the $10 threshold level. Taking the estimated impact under random assignment as the ‚Äútrue‚Äù impact of the program suggests that the difference in difference estimate may be biased. In fact, in this case, using the nonenrolled households as a comparison group does not accurately represent the counterfactual trend in attendance rates."
  },
  {
    "objectID": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#next-page-previous",
    "href": "posts/M&E_01_School_Feeding_Causal_inference_&_Counterfactuals/index.html#next-page-previous",
    "title": "School Feeding Program (SFP) Practical Evaluation Using Different Methodologies and R Codes",
    "section": "Next page previous",
    "text": "Next page previous"
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_Framework/index.html",
    "href": "posts/Monitoring_and_Evaluation_Framework/index.html",
    "title": "How to Develop a Research, Monitoring, and Evaluation Framework for Your Project",
    "section": "",
    "text": "Creating a Research, Monitoring, and Evaluation (M&E) framework is essential for the success of any project. It helps track progress, measure outcomes, and ensure that your project is on track to achieve its goals. In this post, we‚Äôll break down the first part of building an effective M&E framework: Framework Development. We‚Äôll keep things simple and use examples along the way to make it easier to understand.\n\n1. Define the Project Scope and Objectives\nBefore diving into any project, it‚Äôs important to have a clear idea of what you‚Äôre trying to achieve.\n\nProject Overview: Start by summarizing your project. What is it about? Who will benefit? For example, if you‚Äôre working on a project to improve literacy rates in rural schools, your overview might be: ‚ÄúThis project aims to improve literacy rates among children in rural areas by providing better learning materials and training teachers.‚Äù\nSpecific Objectives: These are the concrete steps you plan to take to achieve your overall goal. Remember to make them SMART‚ÄîSpecific, Measurable, Achievable, Relevant, and Time-bound. An example could be: ‚ÄúBy the end of the year, increase reading scores by 20% among students in 10 rural schools.‚Äù\nKey Stakeholders: These are the people who are involved in or affected by your project. For a literacy project, stakeholders might include school principals, teachers, parents, and local government officials.\n\n\n\n2. Develop a Theory of Change (TOC)\nThe Theory of Change (TOC) is like a roadmap that shows how your project activities will lead to the desired results. Here‚Äôs how to develop a TOC:\n\nProblem Statement: Clearly define the issue your project is addressing. For example, ‚ÄúMany students in rural areas struggle with reading due to a lack of proper learning materials and trained teachers.‚Äù\nInputs: These are the resources you‚Äôll need to carry out the project. In our example, this could include funds for buying books, hiring trainers, and creating a teacher training program.\nActivities: These are the things you‚Äôll do to achieve your objectives. For the literacy project, activities might include holding teacher training workshops, distributing reading materials, and organizing reading competitions for students.\nOutputs: These are the direct results of your activities. For example, ‚Äú100 teachers trained and 500 books distributed to schools.‚Äù\nOutcomes: These are the short- and long-term changes you expect to see. Short-term: ‚ÄúTeachers feel more confident in teaching reading.‚Äù Long-term: ‚ÄúStudents improve their reading skills and performance.‚Äù\nImpact: This is the broader, long-term change you hope to achieve. For our project, the impact might be: ‚ÄúImproved literacy rates in rural areas, leading to better opportunities for students.‚Äù\n\n\n\n3. Design Key Performance Indicators (KPIs)\nKey Performance Indicators (KPIs) help you measure the success of your project. These can be broken down into three types:\n\nOutput Indicators: These measure the direct results of your activities. In our example, a good output indicator would be ‚ÄúNumber of teachers trained‚Äù or ‚ÄúNumber of books distributed.‚Äù\nOutcome Indicators: These measure the changes or benefits resulting from your project. For instance, ‚ÄúPercentage of teachers applying new reading techniques in class‚Äù or ‚ÄúIncrease in student reading test scores.‚Äù\nImpact Indicators: These look at the broader, long-term effects. For example, ‚ÄúOverall improvement in literacy rates in the region‚Äù or ‚ÄúPercentage of students who go on to secondary school.‚Äù\n\nBaselines and Targets: It‚Äôs important to know where you‚Äôre starting from and where you want to go. A baseline is the current status before your project begins. For example, you might find that only 40% of students can read at grade level before your intervention. Your target could then be to increase that to 60% by the end of the year.\n\n\nFinal Thoughts\nBuilding the foundation of your Research, Monitoring, and Evaluation framework ensures you have a clear plan for achieving your project‚Äôs goals. By defining your scope and objectives, developing a Theory of Change, and designing strong KPIs, you‚Äôre setting yourself up for success.\nThink of the M&E framework like a compass that helps you navigate your project. With these steps in place, you‚Äôll have a clear sense of direction and will be able to measure your progress along the way. Whether you‚Äôre working on improving literacy or any other type of project, this framework can help guide you to your destination!"
  },
  {
    "objectID": "posts/Monitoring_and_Evaluation_wellness_health/index.html",
    "href": "posts/Monitoring_and_Evaluation_wellness_health/index.html",
    "title": "Monitoring and Evaluation in Health and Wellness: A Statistical Analysis Approach",
    "section": "",
    "text": "Monitoring and evaluation (M&E) play a pivotal role in improving health and wellness programs globally. In this analysis, I focus on coronary artery disease (CAD) prevention, vitamin B complex usage, and addressing common health concerns like dry cough and throat infections. Using data-driven methodologies, I explored how first aid practices, home remedies, and preventive strategies impact health outcomes.\nAs a researcher, I employed the STAR (Situation, Task, Action, Result) framework to structure the analysis. This method not only highlights the challenges and tasks in health monitoring but also suggests actionable solutions backed by statistical models. Using R and Python, I conducted a detailed examination of health indicators from datasets such as the Global Burden of Disease (GBD) dataset and health survey data from the World Health Organization (WHO).\n\nUnderstanding the Situation: Coronary Artery Disease and Vitamin B Complex\nCoronary artery disease (CAD) is a leading cause of mortality worldwide, and early detection and preventive measures are critical. One potential area of interest in preventive health is the role of Vitamin B complex in heart health. Several studies suggest that deficiencies in Vitamin B may contribute to homocysteine build-up, which is linked to an increased risk of CAD.\nThrough a monitoring lens, I examined the correlation between Vitamin B complex intake and CAD incidence across various populations. The data was sourced from the National Health and Nutrition Examination Survey (NHANES), which offers a comprehensive look at health trends in different demographic groups.\nUsing R for data cleaning and Python for machine learning algorithms, I analyzed how CAD risk decreases with increased Vitamin B complex intake. A linear regression model indicated a statistically significant relationship (p &lt; 0.05) between higher Vitamin B complex levels and lower CAD incidence. These results suggest a critical task for public health initiatives: improving Vitamin B intake as a preventive measure against CAD.\n\n\nTask: First Aid and Dry Cough Management\nHealth systems often focus on reactive measures rather than preventive actions. In the context of M&E, first aid practices can be essential for reducing complications in common health issues such as dry cough, which can evolve into severe throat infections if left untreated. By monitoring first aid practices, we can determine their effectiveness in controlling symptoms and preventing progression.\nTo assess this, I used data from the Health Information National Trends Survey (HINTS), which contains self-reported health management practices. The survey responses provided insights into how often individuals resort to home remedies for cough and whether these measures reduce the likelihood of progressing to more severe conditions like throat infections.\nIn Python, I applied a decision tree model to classify cases where first aid (including home remedies) successfully managed cough symptoms. The results showed that early first aid intervention, including the use of Vitamin B complex supplements, effectively reduced the duration and severity of dry cough (accuracy of 83%). This illustrates a strong potential for integrating first aid monitoring into wellness programs to track and evaluate effectiveness.\n\n\nAction: Home Remedies for Cough and Preventing Throat Infections\nHome remedies have long been used for managing coughs, particularly dry coughs that are linked to throat infections. Remedies such as honey, ginger, and steam inhalation are popular among populations that prefer non-pharmaceutical interventions. Monitoring the effectiveness of these remedies is important for understanding how well they work as a first line of defense before medical intervention is sought.\nTo assess the effectiveness of home remedies for cough, I used a sample dataset from Google Health Trends, which tracks search patterns related to health queries like ‚Äúhome remedies for cough‚Äù and ‚Äúthroat infection.‚Äù Using R, I conducted sentiment analysis and time-series forecasting to observe seasonal variations in the popularity of home remedies.\nThe analysis revealed spikes in searches during colder months, correlating with an increase in reported throat infections. Additionally, the data showed that home remedies were perceived as more effective for mild symptoms of dry cough, with a positive sentiment score of 65%. By monitoring these trends, health organizations can better understand public reliance on non-medical interventions and strategize accordingly.\n\n\nResults: Statistical Insights and Recommendations\nThe result of this comprehensive analysis provided valuable insights for health monitoring and evaluation efforts:\n\nVitamin B Complex and Coronary Artery Disease: The linear regression model demonstrated that Vitamin B complex supplementation significantly reduces the risk of CAD. This provides evidence for health programs to advocate for regular intake of this vitamin as part of CAD prevention strategies.\nFirst Aid and Cough Management: Monitoring first aid practices revealed that timely intervention with home remedies can prevent the progression of dry cough to throat infections. Decision tree analysis indicated that home-based care, when applied early, is effective for 83% of individuals experiencing cough symptoms.\nHome Remedies for Cough and Throat Infection: Time-series forecasting from Google Health Trends showed a clear seasonal pattern in home remedy usage, particularly during colder months. This insight allows public health initiatives to tailor awareness campaigns on cough management and throat infection prevention when these remedies are most in demand.\n\n\n\nConclusion\nThis analysis underscores the importance of data-driven monitoring and evaluation in health and wellness programs. From coronary artery disease prevention through Vitamin B complex supplementation to the management of dry cough and throat infections using home remedies, the integration of statistical methodologies offers clear, actionable insights. By leveraging data from sources like NHANES, HINTS, and Google Health Trends, public health organizations can improve the effectiveness of their programs and interventions.\nUltimately, regular monitoring, coupled with evaluation using advanced analytical tools such as R and Python, enables better health outcomes and resource allocation in wellness programs. As the next step, health professionals should consider implementing real-time monitoring dashboards to track the effectiveness of home remedies, first aid interventions, and vitamin supplementation across diverse populations.\n\n\nReferences\n\nNational Health and Nutrition Examination Survey (NHANES)\nReference for Vitamin B complex intake and coronary artery disease (CAD):\n\nCenters for Disease Control and Prevention (CDC). (2021). National Health and Nutrition Examination Survey (NHANES). Retrieved from: https://www.cdc.gov/nchs/nhanes/index.htm\n\nGlobal Burden of Disease (GBD) Dataset\nReference for coronary artery disease global trends and burden:\n\nInstitute for Health Metrics and Evaluation (IHME). (2020). Global Burden of Disease Study 2019 (GBD 2019) Results. Seattle, United States: IHME. Available from: http://ghdx.healthdata.org/gbd-results-tool\n\nHealth Information National Trends Survey (HINTS)\nReference for first aid and dry cough management:\n\nNational Cancer Institute (NCI). (2022). Health Information National Trends Survey (HINTS). Retrieved from: https://hints.cancer.gov/\n\nGoogle Health Trends\nReference for search trends related to home remedies for cough and throat infections:\n\nGoogle. (2024). Google Health Trends Dataset. Retrieved from: https://trends.google.com/trends/\n\nHomocysteine and Coronary Artery Disease Study\nReference for the relationship between homocysteine levels, Vitamin B complex, and CAD:\n\nClarke, R., Halsey, J., Lewington, S., & et al.¬†(2010). Homocysteine and Coronary Heart Disease: Meta-analysis of 30 Studies. JAMA. 288(16):2015‚Äì2022. doi:10.1001/jama.288.16.2015"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Business intelligence tools",
    "section": "",
    "text": "Business Intelligence (BI) tools play a crucial role in turning raw data into actionable insights, aiding decision-makers in making informed choices. In this blog post, we‚Äôll explore the similarities, differences, and unique features of six popular BI tools: Excel, Power BI, Tableau, SAS, Python Dash, and R Shiny. Our analysis will focus on the learning curve and business capability rating of each tool.\n\n\n\nExcel:\n\nSimilarities: Ubiquitous in business for data analysis.\nDifferences: Limited for extensive data processing and visualization.\nUniqueness: Familiar interface but may require advanced functions for complex analytics.\n\nPower BI:\n\nSimilarities: Integrated with Microsoft products.\nDifferences: Emphasis on visualization and dashboards.\nUniqueness: User-friendly, with some learning required for advanced features.\n\nTableau:\n\nSimilarities: Focus on data visualization.\nDifferences: Steeper learning curve; powerful for interactive dashboards.\nUniqueness: Robust visualization capabilities, strong community support.\n\nSAS:\n\nSimilarities: Advanced analytics, statistical analysis.\nDifferences: Requires programming skills; traditional use for complex models.\nUniqueness: Industry-wide usage in healthcare and finance, extensive analytics capabilities.\n\nPython Dash:\n\nSimilarities: Python-based for web-based dashboards.\nDifferences: Programming-centric; suitable for data scientists.\nUniqueness: Flexibility and customization using Python.\n\nR Shiny:\n\nSimilarities: R-based, excellent for statistical analysis.\nDifferences: Requires knowledge of R programming.\nUniqueness: Strong statistical capabilities, ideal for creating interactive web applications.\n\n\n\n\nLearning curve VS Business Capability rating\n\n\n\n\n\n\n\nExcel:\n\nStrengths: Versatile for small to medium-sized datasets.\nWeaknesses: Limited scalability, less advanced analytics.\n\nPower BI:\n\nStrengths: Seamless Microsoft integration, excellent visualizations.\nWeaknesses: May require additional tools for advanced analytics.\n\nTableau:\n\nStrengths: Powerful visualization, extensive data connectivity.\nWeaknesses: Steeper learning curve, higher cost.\n\nSAS:\n\nStrengths: Robust analytics, statistical modeling, and data management.\nWeaknesses: High cost, steeper learning curve.\n\nPython Dash:\n\nStrengths: Customizable with Python, suitable for data science applications.\nWeaknesses: Learning curve for those unfamiliar with Python.\n\nR Shiny:\n\nStrengths: Strong statistical capabilities, great for R users.\nWeaknesses: Learning curve for those unfamiliar with R.\n\n\nIn conclusion, the choice of BI tool depends on specific business needs, data scale, customization requirements, and the existing skill set. Whether opting for user-friendly interfaces or diving into more complex analytics, understanding these tools‚Äô nuances is crucial for effective decision-making."
  },
  {
    "objectID": "posts/post-with-code/index.html#learning-curve",
    "href": "posts/post-with-code/index.html#learning-curve",
    "title": "Business intelligence tools",
    "section": "",
    "text": "Excel:\n\nSimilarities: Ubiquitous in business for data analysis.\nDifferences: Limited for extensive data processing and visualization.\nUniqueness: Familiar interface but may require advanced functions for complex analytics.\n\nPower BI:\n\nSimilarities: Integrated with Microsoft products.\nDifferences: Emphasis on visualization and dashboards.\nUniqueness: User-friendly, with some learning required for advanced features.\n\nTableau:\n\nSimilarities: Focus on data visualization.\nDifferences: Steeper learning curve; powerful for interactive dashboards.\nUniqueness: Robust visualization capabilities, strong community support.\n\nSAS:\n\nSimilarities: Advanced analytics, statistical analysis.\nDifferences: Requires programming skills; traditional use for complex models.\nUniqueness: Industry-wide usage in healthcare and finance, extensive analytics capabilities.\n\nPython Dash:\n\nSimilarities: Python-based for web-based dashboards.\nDifferences: Programming-centric; suitable for data scientists.\nUniqueness: Flexibility and customization using Python.\n\nR Shiny:\n\nSimilarities: R-based, excellent for statistical analysis.\nDifferences: Requires knowledge of R programming.\nUniqueness: Strong statistical capabilities, ideal for creating interactive web applications.\n\n\n\n\nLearning curve VS Business Capability rating"
  },
  {
    "objectID": "posts/post-with-code/index.html#business-capability-rating",
    "href": "posts/post-with-code/index.html#business-capability-rating",
    "title": "Business intelligence tools",
    "section": "",
    "text": "Excel:\n\nStrengths: Versatile for small to medium-sized datasets.\nWeaknesses: Limited scalability, less advanced analytics.\n\nPower BI:\n\nStrengths: Seamless Microsoft integration, excellent visualizations.\nWeaknesses: May require additional tools for advanced analytics.\n\nTableau:\n\nStrengths: Powerful visualization, extensive data connectivity.\nWeaknesses: Steeper learning curve, higher cost.\n\nSAS:\n\nStrengths: Robust analytics, statistical modeling, and data management.\nWeaknesses: High cost, steeper learning curve.\n\nPython Dash:\n\nStrengths: Customizable with Python, suitable for data science applications.\nWeaknesses: Learning curve for those unfamiliar with Python.\n\nR Shiny:\n\nStrengths: Strong statistical capabilities, great for R users.\nWeaknesses: Learning curve for those unfamiliar with R.\n\n\nIn conclusion, the choice of BI tool depends on specific business needs, data scale, customization requirements, and the existing skill set. Whether opting for user-friendly interfaces or diving into more complex analytics, understanding these tools‚Äô nuances is crucial for effective decision-making."
  },
  {
    "objectID": "posts/spatial regression/index.html",
    "href": "posts/spatial regression/index.html",
    "title": "Spartial regression: Lesson3",
    "section": "",
    "text": "Spatial regression is a powerful technique in spatial analytics that allows us to model relationships between variables while accounting for the spatial dependencies inherent in geospatial data. In this advanced blog post, we will dive into the intricacies of spatial regression using R. Our goal is to uncover hidden patterns and relationships in geospatial datasets, focusing on a hypothetical scenario of housing prices and neighborhood characteristics."
  },
  {
    "objectID": "posts/spatial regression/index.html#mastering-spatial-regression-in-r-unveiling-patterns-in-geospatial-data",
    "href": "posts/spatial regression/index.html#mastering-spatial-regression-in-r-unveiling-patterns-in-geospatial-data",
    "title": "Spartial regression: Lesson3",
    "section": "",
    "text": "Spatial regression is a powerful technique in spatial analytics that allows us to model relationships between variables while accounting for the spatial dependencies inherent in geospatial data. In this advanced blog post, we will dive into the intricacies of spatial regression using R. Our goal is to uncover hidden patterns and relationships in geospatial datasets, focusing on a hypothetical scenario of housing prices and neighborhood characteristics."
  },
  {
    "objectID": "posts/spatial regression/index.html#understanding-spatial-regression",
    "href": "posts/spatial regression/index.html#understanding-spatial-regression",
    "title": "Spartial regression: Lesson3",
    "section": "Understanding Spatial Regression",
    "text": "Understanding Spatial Regression\nSpatial regression extends traditional regression models by incorporating spatial relationships. It acknowledges that observations closer in space may exhibit similarities or dependencies that traditional models overlook. There are different types of spatial regression models, and in this blog, we will focus on the Spatial Lag Model.\n\nSpatial Lag Model\nThe Spatial Lag Model introduces a spatially lagged dependent variable, indicating the influence of neighboring observations. Let‚Äôs consider housing prices as the dependent variable and neighborhood characteristics as independent variables.\n# Install and load required packages\ninstall.packages(\"spdep\")\nlibrary(spdep)\n\n# Load geospatial data (housing prices and neighborhood characteristics)\nhousing_data &lt;- st_read(\"path/to/housing_data.shp\")\n\n# Create spatial weights matrix\nw &lt;- poly2nb(st_as_sfc(housing_data))\nlw &lt;- nb2listw(w)\n\n# Fit Spatial Lag Model\nmodel &lt;- lm(y ~ x1 + x2 + lag(y, listw = lw), data = housing_data)\nsummary(model)\n\nReplace ‚Äúpath/to/housing_data.shp‚Äù with the actual path to your Shapefile. This example assumes you have a dependent variable y (housing prices) and independent variables x1 and x2 (neighborhood characteristics)."
  },
  {
    "objectID": "posts/spatial regression/index.html#interpretation-of-results",
    "href": "posts/spatial regression/index.html#interpretation-of-results",
    "title": "Spartial regression: Lesson3",
    "section": "Interpretation of Results",
    "text": "Interpretation of Results\nThe summary output provides information about coefficients, standard errors, and statistical significance. Pay special attention to the spatial lag coefficient, which indicates the impact of neighboring observations on the dependent variable."
  },
  {
    "objectID": "posts/spatial regression/index.html#diagnostic-checks",
    "href": "posts/spatial regression/index.html#diagnostic-checks",
    "title": "Spartial regression: Lesson3",
    "section": "Diagnostic Checks",
    "text": "Diagnostic Checks\nAssess the model‚Äôs validity and assumptions through diagnostic checks.\n# Spatial autocorrelation of residuals\nresiduals &lt;- residuals(model)\nmoran.test(residuals, listw = lw)\n\nA significant Moran‚Äôs I statistic for residuals indicates spatial autocorrelation, suggesting the need for further model refinement."
  },
  {
    "objectID": "posts/spatial regression/index.html#visualization",
    "href": "posts/spatial regression/index.html#visualization",
    "title": "Spartial regression: Lesson3",
    "section": "Visualization",
    "text": "Visualization\nVisualize the spatial patterns and regression results on a map.\n# Plotting observed vs. predicted values\nplot(housing_data$y, fitted(model), main = \"Observed vs. Predicted\", xlab = \"Observed\", ylab = \"Predicted\")\n\n# Spatial autocorrelation map of residuals\nspplot(residuals, main = \"Spatial Autocorrelation Map of Residuals\", col.regions = colorRampPalette(c(\"blue\", \"white\", \"red\")))\n\nThese visualizations help in understanding how well the model captures spatial patterns and where adjustments might be needed."
  },
  {
    "objectID": "posts/spatial regression/index.html#conclusion",
    "href": "posts/spatial regression/index.html#conclusion",
    "title": "Spartial regression: Lesson3",
    "section": "Conclusion",
    "text": "Conclusion\nSpatial regression in R opens up new dimensions for analyzing geospatial data. In this blog post, we explored the Spatial Lag Model as an advanced technique for modeling spatial dependencies in housing prices and neighborhood characteristics. The interpretation of results, diagnostic checks, and visualizations are crucial components of spatial regression analysis.\nAs you venture into spatial analytics, consider exploring other spatial regression models, incorporating additional spatial variables, and applying advanced techniques to enhance the robustness of your models. Stay tuned for more advanced spatial analytics topics, including machine learning with geospatial data and building interactive web maps. Happy analyzing!"
  },
  {
    "objectID": "posts/Survey_guidelines/index.html",
    "href": "posts/Survey_guidelines/index.html",
    "title": "Survey tools",
    "section": "",
    "text": "Choosing the right survey tools is paramount to successful data collection. Opt for platforms like SurveyMonkey, Google Forms, or REDCap for their user-friendly interfaces and adaptability. These tools enable customization of surveys, facilitating the incorporation of context-specific questions for both household and agricultural data.\nExample:\nImagine you are collecting agricultural data on crop yields. Use SurveyMonkey to craft dynamic surveys that adjust based on respondents‚Äô previous answers. If a farmer indicates they grow wheat, subsequent questions can automatically shift to focus on wheat-specific variables, streamlining the data collection process.\n\n\n\nEnsuring data quality in data collection tools is crucial to obtain reliable and accurate information. Here are some key practices to help ensure data quality:\n\nClear and Well-Defined Data Collection Protocols:\n\nClearly define the purpose of data collection.\nDevelop standardized data collection protocols, including detailed instructions for data collectors.\nProvide examples and guidelines for each data entry field.\n\nTraining and Capacity Building:\n\nConduct thorough training sessions for data collectors, ensuring they understand the data collection process and tools.\nInclude training on the importance of data quality, potential challenges, and how to address them.\nRegularly update the training to incorporate any changes or improvements.\n\nUse of Validated and Reliable Tools:\n\nChoose data collection tools that are validated and have a track record of reliability.\nRegularly update and patch software to address any bugs or security issues.\nConsider user-friendly interfaces to minimize errors during data entry.\n\nPre-Testing and Piloting:\n\nBefore full-scale data collection, conduct pre-testing or piloting to identify and address potential issues.\nEvaluate the effectiveness of data collection tools in a controlled environment.\n\nData Validation Checks:\n\nImplement validation checks in data collection tools to ensure the accuracy and integrity of entered data.\nUse range checks, logical checks, and consistency checks to identify and prevent errors.\n\nReal-Time Data Monitoring:\n\nMonitor incoming data in real-time to detect anomalies or inconsistencies.\nImplement automated alerts for data quality issues, enabling immediate corrective actions.\n\nStandardized Coding and Classification:\n\nUse standardized coding and classification systems to ensure consistency across data entries.\nProvide clear definitions for each code or category to minimize misinterpretation.\n\nRandom Audits and Quality Assurance Checks:\n\nConduct random audits of collected data to verify its accuracy.\nEstablish a quality assurance team to regularly review a subset of collected data for consistency and completeness.\n\nUser Feedback Mechanism:\n\nEncourage users to provide feedback on data collection tools and processes.\nEstablish a feedback mechanism to address issues reported by data collectors promptly.\n\nData Cleaning and Deduplication:\n\nRegularly perform data cleaning procedures to correct errors, inconsistencies, and missing values.\nImplement deduplication processes to identify and resolve duplicate entries.\n\nDocumentation and Metadata:\n\nDocument the data collection process, including the data dictionary, variable definitions, and any transformations applied.\nMaintain clear metadata to provide context for each dataset.\n\nRegular Review and Continuous Improvement:\n\nSchedule regular reviews of data collection processes and tools.\nContinuously seek feedback from data collectors and stakeholders to identify areas for improvement."
  },
  {
    "objectID": "posts/Survey_guidelines/index.html#selecting-program-survey-tools",
    "href": "posts/Survey_guidelines/index.html#selecting-program-survey-tools",
    "title": "Survey tools",
    "section": "",
    "text": "Choosing the right survey tools is paramount to successful data collection. Opt for platforms like SurveyMonkey, Google Forms, or REDCap for their user-friendly interfaces and adaptability. These tools enable customization of surveys, facilitating the incorporation of context-specific questions for both household and agricultural data.\nExample:\nImagine you are collecting agricultural data on crop yields. Use SurveyMonkey to craft dynamic surveys that adjust based on respondents‚Äô previous answers. If a farmer indicates they grow wheat, subsequent questions can automatically shift to focus on wheat-specific variables, streamlining the data collection process.\n\n\n\nEnsuring data quality in data collection tools is crucial to obtain reliable and accurate information. Here are some key practices to help ensure data quality:\n\nClear and Well-Defined Data Collection Protocols:\n\nClearly define the purpose of data collection.\nDevelop standardized data collection protocols, including detailed instructions for data collectors.\nProvide examples and guidelines for each data entry field.\n\nTraining and Capacity Building:\n\nConduct thorough training sessions for data collectors, ensuring they understand the data collection process and tools.\nInclude training on the importance of data quality, potential challenges, and how to address them.\nRegularly update the training to incorporate any changes or improvements.\n\nUse of Validated and Reliable Tools:\n\nChoose data collection tools that are validated and have a track record of reliability.\nRegularly update and patch software to address any bugs or security issues.\nConsider user-friendly interfaces to minimize errors during data entry.\n\nPre-Testing and Piloting:\n\nBefore full-scale data collection, conduct pre-testing or piloting to identify and address potential issues.\nEvaluate the effectiveness of data collection tools in a controlled environment.\n\nData Validation Checks:\n\nImplement validation checks in data collection tools to ensure the accuracy and integrity of entered data.\nUse range checks, logical checks, and consistency checks to identify and prevent errors.\n\nReal-Time Data Monitoring:\n\nMonitor incoming data in real-time to detect anomalies or inconsistencies.\nImplement automated alerts for data quality issues, enabling immediate corrective actions.\n\nStandardized Coding and Classification:\n\nUse standardized coding and classification systems to ensure consistency across data entries.\nProvide clear definitions for each code or category to minimize misinterpretation.\n\nRandom Audits and Quality Assurance Checks:\n\nConduct random audits of collected data to verify its accuracy.\nEstablish a quality assurance team to regularly review a subset of collected data for consistency and completeness.\n\nUser Feedback Mechanism:\n\nEncourage users to provide feedback on data collection tools and processes.\nEstablish a feedback mechanism to address issues reported by data collectors promptly.\n\nData Cleaning and Deduplication:\n\nRegularly perform data cleaning procedures to correct errors, inconsistencies, and missing values.\nImplement deduplication processes to identify and resolve duplicate entries.\n\nDocumentation and Metadata:\n\nDocument the data collection process, including the data dictionary, variable definitions, and any transformations applied.\nMaintain clear metadata to provide context for each dataset.\n\nRegular Review and Continuous Improvement:\n\nSchedule regular reviews of data collection processes and tools.\nContinuously seek feedback from data collectors and stakeholders to identify areas for improvement."
  },
  {
    "objectID": "posts/Wildlife tourism revenue/index.html",
    "href": "posts/Wildlife tourism revenue/index.html",
    "title": "The Growing Importance of Wildlife Economy: A Path to Sustainable Growth",
    "section": "",
    "text": "The Growing Importance of Wildlife Economy: A Path to Sustainable Growth\nThe global wildlife economy plays a crucial role in fostering sustainable development, preserving biodiversity, and providing economic benefits to local communities. By closely monitoring metrics like biodiversity health, tourism revenue, and local employment in wildlife enterprises, stakeholders‚Äîgovernments, donors, and investors‚Äîcan effectively support a balance between economic growth and conservation. This blog post breaks down the significance of these metrics and why they are essential in shaping policies and investment strategies for wildlife economies.\n\nUnderstanding the Metrics that Matter\nIn the context of the wildlife economy, three critical metrics stand out as indicators of both ecological and economic health:\n\n\nBiodiversity Health Index\nThis index provides insight into the status of wildlife populations and ecosystems. It tracks the number of species, their population trends, and conservation status. Understanding biodiversity health is essential to ensuring the long-term viability of wildlife tourism and related industries. If species are endangered or habitats are declining, the economic benefits from these activities will eventually diminish. This index helps determine the future sustainability of wildlife-based economies, guiding conservation policies and actions (FAO, 2020).\n\nTourism Revenue from Wildlife-Based Activities\nWildlife tourism is a significant revenue source, especially for countries rich in biodiversity, such as Kenya, Tanzania, and Australia. The revenue generated from activities like safaris, ecotourism, and marine wildlife experiences helps local and national economies thrive. For instance, in 2023, Kenya and South Africa experienced a growth of up to 25% in their wildlife tourism revenue, highlighting the importance of sustainable tourism in post-pandemic recovery. Monitoring tourism revenue is critical as it provides governments and investors with data to craft policies that support tourism infrastructure, promote conservation, and ensure long-term growth in the sector (WTTC, 2023).\n\nLocal Community Employment and Income from Wildlife Enterprises\nThis metric assesses how wildlife enterprises contribute to the livelihoods of local communities. Activities like ecotourism, wildlife management, and conservation provide employment opportunities and generate income, especially in rural areas. The positive economic impacts from these activities are evident in countries like Uganda and Costa Rica, where ecotourism has seen significant growth, with revenue increases of 15-20% from 2022 to 2023. For governments and donors, this metric underscores the role of wildlife enterprises in poverty alleviation and community development. Supporting these activities with funding and infrastructure can help lift communities out of poverty while promoting sustainable wildlife management practices (UNWTO, 2022).\n\n\n\nThe 2022-2023 Revenue Shift: What It Means\nThe wildlife tourism industry has shown remarkable resilience and growth in recent years, especially between 2022 and 2023. Countries heavily dependent on wildlife tourism, such as Kenya, South Africa, and Tanzania, experienced significant increases in revenue‚Äîranging from $900M to $1.7B‚Äîas tourists returned post-pandemic. This surge demonstrates the sector‚Äôs potential to drive economic recovery and growth.\nHere‚Äôs a breakdown of how the revenue shifted from 2022 to 2023 across a selection of countries:\n\n\n\n\n\n\n\n\n\nCountry\n2022 Revenue (USD)\n2023 Revenue (USD)\nChange (%)\n\n\n\n\nKenya\n$1.2B\n$1.5B\n+25%\n\n\nSouth Africa\n$900M\n$1.1B\n+22%\n\n\nTanzania\n$750M\n$900M\n+20%\n\n\nAustralia\n$1.5B\n$1.7B\n+13%\n\n\nMauritius\n$300M\n$410M\n+37%\n\n\nBotswana\n$320M\n$450M\n+41%\n\n\n\n\nThis chart clearly shows the growing importance of wildlife tourism in global economies, particularly in African and island nations. Governments, donors, and investors should recognize the need to continue investing in conservation efforts, sustainable tourism infrastructure, and local community development to sustain this growth.\n\n\nImplications for Governments, Donors, and Investors\n\nFor Governments:\nGovernments should focus on creating policies that not only protect biodiversity but also ensure that the revenue generated from wildlife tourism is reinvested into conservation and local communities. Strengthening tourism infrastructure, offering incentives for sustainable practices, and implementing environmental protection laws are essential to maintaining the growth of this sector (World Bank, 2022).\nFor Donors:\nDonors can contribute by funding community-based conservation programs, supporting sustainable wildlife tourism initiatives, and helping build local capacity. Their investments can help drive the inclusion of local communities in wildlife tourism, enhancing their participation in conservation efforts while simultaneously improving their livelihoods (Global Environment Facility, 2023).\nFor Investors:\nInvestors should recognize wildlife tourism as a profitable sector with significant growth potential. With revenue increases and demand for sustainable experiences on the rise, investors can explore opportunities in eco-resorts, wildlife conservation partnerships, and eco-tourism ventures. Strategic investments will ensure long-term returns while promoting conservation (International Finance Corporation, 2022).\n\n\n\nConclusion\nThe wildlife economy is a dynamic and critical sector for both biodiversity and economic development. By focusing on key metrics like biodiversity health, tourism revenue, and local community benefits, governments, donors, and investors can work together to promote sustainable growth that benefits both people and wildlife. As the sector continues to rebound post-pandemic, these efforts will ensure that wildlife economies thrive for generations to come.\n\n\nReferences and Further Reading\n\nFAO. (2020). The State of World‚Äôs Biodiversity for Food and Agriculture. Food and Agriculture Organization. Link to report.\nWTTC. (2023). Economic Impact Report 2023. World Travel and Tourism Council. Link to report.\nUNWTO. (2022). Tourism and Biodiversity Report. United Nations World Tourism Organization. Link to report.\nWorld Bank. (2022). Tourism for Sustainable Development. Link to report.\nGlobal Environment Facility. (2023). Funding Biodiversity Conservation Projects. Link to report.\nInternational Finance Corporation. (2022). Sustainable Investment in Tourism. Link to report."
  },
  {
    "objectID": "courses/python.html",
    "href": "courses/python.html",
    "title": "python",
    "section": "",
    "text": "This course outlines the ‚Ä¶ bla bla bla‚Ä¶\nGo tho"
  },
  {
    "objectID": "00_pay_m&_E.html",
    "href": "00_pay_m&_E.html",
    "title": "pay_ai_m&e",
    "section": "",
    "text": "Click the button below to pay for this course using Mastercard, M-Pesa, or Visa.\nAfter payment, you will receive your access credentials via email.\n\nPay Now"
  },
  {
    "objectID": "00_pay_m&_E.html#ai-for-me-masterclass-access",
    "href": "00_pay_m&_E.html#ai-for-me-masterclass-access",
    "title": "pay_ai_m&e",
    "section": "",
    "text": "Click the button below to pay for this course using Mastercard, M-Pesa, or Visa.\nAfter payment, you will receive your access credentials via email.\n\nPay Now"
  }
]